---
output:
  pdf_document: default
  html_document: default
---
# Medidas de desigualdade

O assunto sobre medidas de desigualdade está baseada na sua totalidade no capítulo 17 de @Hoffmann2006

## Príncipio de Pigou-Dalton

A condição de Pigou-Dalton define que as medidas de desigualdades devem ter seus valores aumentados quando há transferência regressivas de renda.
Para entender a condicção de Pigou-Dalton, considere uma população com apenas duas pessoas cujas rendas são $X_1$ e $X_2$. Então, $\mu = \frac{X_1 + X_2}{2}$. No caso de perfeita igualdade, $X_1 = X_2 = \mu$. No caso de uma distribuição com $X_1 \neq X_2$, uma transferência de renda do mais pobre para o mais rico, mantendo a renda média constante, aumenta o grau de desigualdade.

## Transferência Regressiva

Essa tranferência de renda do mais pobre para o mais rico, mantida a renda média constante, é denominada como **transferência regressiva** de renda. Portanto, uma **transferência progressiva** é a transferência de renda do mais rico para o mais pobre.


## Curva de Lorenz

Table: (\#tab:pessoasocupadas) Distribuição de pessoas ocupadas conforme renda obtida na atividade exercida no Brasil, de acordo com a PNAD 2003 

-------------------------------------------------------------------------
            % no estrato    % no estrato   % acumulada    % acumulada     
  estrato   da população      da renda     da população   da renda        
                 (%)             (%)         (100$p$)     (100$\Phi$)     
--------- ---------------- -------------- -------------- ---------------- 
      I         30                7             30                 7       

     II         20                9             50                16       

    III         20               13             70                29       

     IV         10               10             80                39       

      V         10               16             90                55       

     VI          5               13             95                68       

    VII          4               19             99                87       

   VIII          1               13            100               100       
-------------------------------------------------------------------------

Considere os dados da tabela \@ref(tab:pessoasocupadas). Na coluna de porcentagem acumulada podemos observar que 70% da população possui 29% da renda. Os percentuais acumlados da população $p$ e da renda $\Phi$ formam um plano cartesinao $(p,\Phi)$ originando a Cuirva de Lorenz. 


```{r CurvaLorenzR, echo=TRUE, fig.cap="Curva de Lorenz"}
library(ineq)
# usando os valores do exemplo em porcentagem mesmo
p <- c(30,20,20,10,10,5,4,1)
r <- c(7,9,13,10,16,13,19,13)

# calcula o mínimo da curva de Lorenz
Lc.min <- Lc(r, n = p)
# Desenha a curva de Lorenz em um gráfico
plot(Lc.min)
```
Considerando a curva de Lorenz, figura \@ref(fig:CurvaLorenz), que é basicamente a obtida pelo R, figura \@ref(fig:CurvaLorenzR), mas com algumas indicações, é possível obter algumas definições.

```{r CurvaLorenz, fig.align = 'center', out.width = '100%', fig.cap = "A curva de Lorenz com algumas indicações"}

knitr::include_graphics("lorenz3.png")
```

A área que corresponde a letra $a$ é denominada área de desigualdade. o seguimento de retas $\overline{AB}$ é chamado de *linha de perfeita igualdade* onde $p=\Phi$ e a área de de desigualdade é zero.

Analisando o casos de máxima desigualdade:

- excluindo-se o fato de renda negativa, considere que apenas um de $n$ indíviduos receba toda a renda e os demais $n-1$ indivíduos recebam zero de renda.
- Neste caso a pocentagem de renda é zero até o ponto $\dfrac{n-1}{n}$ no eixo horizontal, tornando-se $\Phi = 1$ ao se incluir o último indíviduo.
- Neste caso, a Curva de Lorenz é dada pela poligonal $\widehat{ABC}$ e a área de desigualdade máxima é o triângulo $ABC$.


## Índice Gini

Considere os dados da tabela \@ref(tab:pessoasocupadas). Seja $p$ o valor da proporção acumulada da população até certo estrato e seja $\Phi$ o valor da correspondente proporção acumulada da renda. Os pares de valores $(p,\Phi)$, para os diversos estratos, definem pontos em um sistema de eixos cartesianos como aparece na figura \@ref(fig:CurvaLorenz). Estes pontos estão sobre a curva de Lonrez, que mostra como a porporção acumulada da renda $(\Phi)$ varia em função da proporção acumulada da população $(p)$, com as pessoas ordenadas de acordo com valores crescentes da renda. A área correspondente a $a$ que está entre a reta AB e a curva de Lorenz na figura \@ref(fig:CurvaLorenz), é denominada **área de desigualdade**.

Para entender como ocorre a variação desta área de desigualdade, a área $a$, primeiro considere uma situação de distribuição de renda com perfeita igualdade, ou seja, uma população em que todos recebem a mesma renda.Nesta situação, a uma população $p$ da população corresponde uma igual proporção $\Phi$ da renda total, ou seja, $\Phi = p$. Portanto, a curva de Lorenz dessa distribuição coincide com a reta AB da figura \@ref(fig:CurvaLorenz), denominado, por isso, de **linha de perfeita igualdade**. Neste caso a área de desigualdade é igual a zero.

Considere agora uma outra situação, uma distribuição de renda com o máximo de desigualdade. Considerando que **não** existe a possibilidade de renda negativa, esse seria o caso de uma população com $n$ pessoas, em que uma delas recebe toda a renda e as $n-1$ restante receba zero de renda. Nesta situação, a proporção acumulada da renda é igual a zero até o ponto do eixo horizontal (abcissa) $\frac{(n-1)}{n}$, tornando-se $\Phi = 1$ quando se se inclui a pessoa que recebe toda a renda. Neste caso, a curva de Lorenz passa a ser a poligonal ABC da figura \@ref(fig:CurvaLorenz). Que é numericamente igual a 0,5 (Por quê?).

Por definição, o **índice de Gini (G)** é uma relação entre a área de desigualdade, indicada por $a$ que passar a ser denominada de $\alpha$, e a área do triângulo ABC que é numericamente igual a 0,5, ou seja,

\[
G = \dfrac{\alpha}{0,5} = 2\alpha
(\#eq:Gini)
\]

A fórmula \@ref(eq:Gini) é uma das fórmulas de Gini que tem utilidade do ponto de vista teórico.Uma vez que

\[
0 \leq \alpha \leq 0,5
\]

tem se que

\[
0 \leq G \leq 1
\]

Ou seja de que o índice de Gini varia entre entre zero, ausência de desigualdade, e um, máxima desigualdade.Adicionalmente, o índice de Gini é um número adimensional.

Uma fórmula alternativa e mais prática do ponto de vista do cálculo do índice de Gini pode ser obitda considerando-se uma distribuição discreta.

Seja uma variável aleatória discreta $X_i$ para $i=1,\ldots,n$, cujos valores estão em ordem crescente

\[
X_1\leq X_2 \leq \ldots \leq X_{n-1} \leq X_n
\]
admitindo-se que os n valores são igualmente prováveis. 

a proporção acumulada do número de elementos,m até o i-ésimo elemento, é

\[
p_i = \dfrac{i}{n},~\text{para}~i =1,\ldots, n
(\#eq:ProporcaoDaPopulacao)
\]

A correspondente proporção acumulada de $X$, até o i-ésimo elemento é

\[
\Phi_i = \dfrac{\sum_{j=1}^{i}X_j}{\sum_{j=1}^{n}X_j} = \dfrac{1}{n\mu}\sum_{j=1}^{i}X_j
(\#eq:ProporcaoDaRendaAcumulada)
\]
onde
\[
\mu = \dfrac{1}{n}\sum_{j=1}^{n}X_j
\]
Se $X$ representa a renda individual e se $X_j < X_{j+1}$, $\Phi_i$ representa a fração da renda total apropriada pelas pessoas com renda inferior ou igual a $X_i$. As expressões \@ref(eq:ProporcaoDaPopulacao) e \@ref(eq:ProporcaoDaRendaAcumulada) definem as coordenadas $(p_i,\Phi_i)$ com $i=1,\ldots, n$ de $n$ pontos da curva de Lorenz. A rigor não existe, nesse caso, uma curva, mas uma poligonal cujos vértices são a origemdos exios e os pontos de coordenadas $(p_i,\Phi_i)$.

Na sequência é apresentada de forma resumida como se calcula o índice de Gini a partir dos valores de $X_i$ para $i = 1,\ldots ,n$ da variável. Na figura \@ref(fig:CurvaLorenz) a soma das áreas $a$ e $b$ totaliza a área do polígono ABC que numericamente é igual a 0,5. 
Portanto, $a = 0,5 - b$. Ou seja, colocando na notação mais elegante,

\[
\alpha = 0,5 - \beta.
(\#eq:alfa)
\]
Substituindo \@ref(eq:alfa) em \@ref(eq:Gini) obtém-se

\[
G = \dfrac{0,5 - \beta}{0,5} = 1 - 2\beta.
(\#eq:GiniEmTermosDeBeta)
\]
Note que a área abaixo da "curva" de Lorenz pode ser representada, de forma aproximada, como a soma das áreas de $n$ trapézios um do lado do outro. Desta forma, a área $b$ da figura \@ref(fig:CurvaLorenz), compreendida entre a poligonal de Lorenz e o eixo das abscissas, é obtida somando-se a área dos $n$ trapézios. Ou seja, a área do i-ésimo trapézio é
\[
S_i = \dfrac{\Phi_{i-1} + \Phi_i}{2}\times \dfrac{1}{n}
(\#eq:AreaDoTrapezioSi)
\]
onde $\Phi_{i-1}$ é a base menor do i-ésimo trapézio; $\Phi_i$ é a base maior do i-ésimo trapézio e; $1/n$ é a altura do trapézio que corresponde a pessoa da população composta por n pessoas.

Note que o valor de $\Phi_0 = 0$, ou seja, o valor de $\Phi_{i-1}$ para $i=1$. Com base na fórmula \@ref(eq:AreaDoTrapezioSi) é possível obter a área corresponde a $b$ na figura \@ref(fig:CurvaLorenz) ou $\beta$ nas notações matemáticas no texto

\[
\beta = \sum_{i=1}^{n}S_i = \dfrac{1}{2n}\sum_{i=1}^{n}(\Phi_{i-1} + \Phi_i)
(\#eq:AreaDoBeta)
\]
Substituindo \@ref(eq:AreaDoBeta) em \@ref(eq:GiniEmTermosDeBeta), obtém-se

\[
G = 1 - \dfrac{1}{n}\sum_{i=1}^{n}(\Phi_{i-1} + \Phi_i)
(\#eq:GiniEmTermosDePhi)
\]
Considerando a fórmula \@ref(eq:ProporcaoDaRendaAcumulada) e que $\Phi_0 = 0$, se obtém o índice de Gini em termos da variável $X_i$. Ou seja,

\[
G = 1 - \dfrac{1}{n^2\mu}[(2n-1)X_1 + (2n-3)X_2 + \dots + 3X_{n-1} + 1X_n]
(\#eq:GiniEmTermosDeXi)
\]

Na parte sobre Estatística Descritiva foi apresentada a medida de dispersão chamada Diferença Absoluta Média que é dada por

\[
\Delta = \dfrac{1}{n^2}\sum_{i=1}^{n}\sum_{j=1}^{n}|X_i - X_j|
(\#eq:DiferencaAbsolutaMedia)
\]

Trabalhando algebricamente a fórmula \@ref(eq:DiferencaAbsolutaMedia)

\[
\Delta = 2\mu - \dfrac{2}{n^2}[(2n-1)X_1 + (2n-3)X_2 + \dots + 3X_{n-1} + 1X_n]
(\#eq:DiferencaAbsolutaMediaModificada)
\]

Se dividir \@ref(eq:DiferencaAbsolutaMediaModificada) por $2\mu$ obtém a fórmula do índice de Gini em termos da medida de dispersão Diferença Absoluta Média

\[
G = \dfrac{\Delta}{2\mu}
(\#eq:GiniEmTermosDeDiferencaAbsolutaMedia)
\]

Tratando-se da distribuição da renda em uma população, a relação \@ref(eq:GiniEmTermosDeDiferencaAbsolutaMedia) mostra que o índice de Gini, como medida de do grau de desigualdade, apresenta a vantagem de medir diretamente as diferenças de rendal, levando em consideração diferenças entre as rendas de **todos** os pares de pessoas.

Como $\Delta$ é uma medida de dispersão da distribuição, a relação \@ref(eq:GiniEmTermosDeDiferencaAbsolutaMedia) mostra que o índice de Gini é uma medida de dispersão relativa. Assim, o conceito de desigualdade de uma distribuição se confunde com o conceito de dispersão relativa.

Com um desenvolvimento algébrico de $\Delta$ é possível transformar a fórmula \@ref(eq:GiniEmTermosDeDiferencaAbsolutaMedia) em

\[
G = \dfrac{2}{n^2\mu}\sum_{i=1}^{n} iX_i - \dfrac{1}{n} - 1
(\#eq:GiniFinal)
\]
A relação \@ref(eq:GiniFinal) mostra que, no cálculo do índice de Gini, cada valor de $X_i$ da variável aparece poderado por $i$. Ou seja, $X_i$ aparece poderada pelo respectivo número de ordem na sequência dos valores ordenados.

**Exemplo numérico**

Para aplicar a fórmula do índice de Gini, utiliza-se os dados apresentados na tabela abaixo, obtidos de @Hoffmann2006.

Table: (\#tab:DadosdoExemploNumericoParaGini) Valores de $X_i$, $p_i$, $\Phi_i$ e $\Phi_{i-1} + \Phi_i$ para a população hipotética de 8 elementos

-----------------------------------------------------------------------------------------------------
    $i$           $p_i$         $X_i$       $\sum_{j=1}^{n}X_j$   $\Phi_i$   $\Phi_{i-1} + \Phi_i$
 ----------- -------------- -------------- --------------------- ---------- -----------------------
     1          0,125             1                 1               0,02              0,02          

     2          0,250             1                 2               0,04              0,06          

     3          0,375             1                 3               0,06              0,10          

     4          0,500             2                 5               0,10              0,16          

     5          0,625             4                 9               0,18              0,28          
     
     6          0,750             8                17               0,34              0,52          
     
     7          0,875            13                30               0,60              0,94          
     
     8          1,000            20                50               1,00              1,60          
-----------------------------------------------------------------------------------------------------

Com essas informações é possível calcular o índice de Gini, através de \@ref(eq:GiniEmTermosDePhi)

\[
G = 1 - \dfrac{1}{n}\sum_{i=1}^{n}(\Phi_{i-1} + \Phi_i);
\]

através de \@ref(eq:GiniEmTermosDeDiferencaAbsolutaMedia)

\[
G = \dfrac{\Delta}{2\mu},
\]
onde
\[
\Delta = \dfrac{1}{n^2}\sum_{i=1}^{n}\sum_{j=1}^{n}|X_i - X_j|
\]
e
\[
\mu = \sum_{i=1}^{n}X_i;
\]
e através de \@ref(eq:GiniFinal)

\[
G = \dfrac{2}{n^2\mu}\sum_{i=1}^{n} iX_i - \dfrac{1}{n} - 1
\]
Usando \@ref(eq:GiniEmTermosDePhi), é necessário totalizar a coluna $\Phi_{i-1} + \Phi_i$ na tabela \@ref(tab:DadosdoExemploNumericoParaGini). Ou seja,

```{r somandosomadephis}
options(OutDec = ",")
somaphis <- c(0.02, 0.06, 0.1, 0.16, 0.28, 0.52, 0.94, 1.60)
somasomaphis <- sum(somaphis)
somasomaphis
```

\[
\sum_{i+1}^{8} (\Phi_{i-1} + \Phi_i) = `r somasomaphis`
\]

Portanto
```{r ginicomphis, echo=TRUE}
giniphis <- 1 - 1/length(somaphis)*somasomaphis
giniphis
```

\[
G = 1 - \dfrac{1}{8}\times `r somasomaphis` = `r giniphis`
\]

Para aplicar a fórmula \@ref(eq:GiniEmTermosDeDiferencaAbsolutaMedia) que é a fórmula do índice de Gini em termos de diferença absoluta média, $\Delta$, é necessário calcular a diferença absoluta média com base nos dados de $X_i$ da tabela \@ref(tab:DadosdoExemploNumericoParaGini).

```{r duplasomadiferencaabsoluta}
xi <- c(1,1,1,2,4,8,13,20)

XC <- matrix(xi,  nrow = length(xi), ncol = length(xi), byrow = FALSE)
XC

XL <- matrix(xi, nrow = length(xi), ncol = length(xi), byrow = TRUE)
XL

DIFX <- XC - XL
DIFX

ABSDIFX <- abs(DIFX)
ABSDIFX

iota <- matrix(1, nrow = length(xi), ncol = 1, byrow = TRUE)
iota

somacolunaABSDIFX <- t(iota) %*% ABSDIFX
somacolunaABSDIFX

somalinhasomacolunaABSDIFX <- somacolunaABSDIFX %*% iota
somalinhasomacolunaABSDIFX

obs <- length(xi)

delta <- obs^(-2)*somalinhasomacolunaABSDIFX
delta

```

Ou seja,

\[
\Delta = \dfrac{1}{n^2}\sum_{i=1}^{n}\sum_{j=1}^{n}|X_i - X_j| = \dfrac{1}{(`r obs`)^2} \times `r somalinhasomacolunaABSDIFX` = `r delta`
\]

Com a diferença absoluta média de $X_i$ devidamente calculada, aplica-se a fórmula \@ref(eq:GiniEmTermosDeDiferencaAbsolutaMedia)

```{r GiniEmDelta, echo=TRUE}
ximedio <- sum(xi)/length(xi)
ximedio

ginidelta <- delta/(2*ximedio)
ginidelta
```

\[
  G = \dfrac{\Delta}{2\mu} = \dfrac{`r delta`}{2 \times `r ximedio`} = `r ginidelta`
\]

Para aplicar a fórmula \@ref(eq:GiniFinal) na obtenção do índice de Gini é necessário ponderar cada valor de $X_i$ pela sua respectiva ordem $i$ e soma todos os respectivos produtos

\[
  \sum_{i=1}^{n}iX_i.
\]

usando os dados da tabela \@ref(tab:DadosdoExemploNumericoParaGini)

```{r GiniFinal, echo=TRUE}
is <- matrix(1:length(xi), nrow = length(xi), ncol = 1, byrow = TRUE)
is

ixi <- t(is) * xi
ixi

somaixi <- sum(ixi)
somaixi

ginifinal <- 2/(obs^2 * ximedio)*somaixi - obs^(-1) - 1
ginifinal
```

obtém

\[
  G = \dfrac{2}{n^2\mu}\sum_{i=1}^{n} iX_i - \dfrac{1}{n} - 1 = \dfrac{2}{`r obs`^2 \times `r ximedio`}\times `r somaixi` - \dfrac{1}{`r obs`} - 1 = `r ginifinal`
\]

## Discrepância Máxima

Discrepância Máxima é a maior distância entre entre a linha AB e a curva de Lorenz da figura \@ref(fig:CurvaLorenz). Portanto, a discrepância máxima é a diferença máxima entre a relação da porcentagem acumulada da população e a sua respectiva porcentagem acumulada da renda numa situação de exata igualdade dada pela reta AB e a relação da porcentagem acumulada da população e a sua respectiva porcentagem acumulada da renda numa situação de desigualdade entre as pessoas dessa população que na figura corresponde a poligonal da curva de Lorenz. De acordo com @Hoffmann2006

\[
  D = p_h - \Phi_h
  (\#eq:DiscrepanciaMaximaDefinicao)
\]

Portanto, o cálculo de $D$ através de \@ref(eq:DiscrepanciaMaximaDefinicao) depende de $h$, um número inteiro positivo. Encontrando-se $i=h$ encontra-se a discrepância máxima $D$.

Seja uma sequência de valores ordenados em ordem crescente de uma variável discreta $X_i$

\[
  X_1 \leq X_2 \leq \ldots \leq X_n
\]

sendo válida pelos menos uma desigualdade. 

Para o cálculo da discrepância máxima, é importante entender que a mesma ocorre quando a inclinação do segmento da poligonal da curva de Lorenz passa de uma valor menor que um para um valor maior que um. De acordo com @Hoffmann2006, a inclinação do segmento da poligonal é dada por

\[
  d_i = \dfrac{X_i}{\mu}
\]

Essa mudança é identificada quando o valor de $X_i$ ordenada em ordem crescente passa de uma valor menor que a média $\mu$ para um valor maior que a média $\mu$, ou seja,

\[
  X_i < \mu~~para~1 \leq i \leq h
\]
e
\[
  X_i \geq \mu~~para~h < i \leq n
\]

Nesaas condições percorre-se a sequência de valores em ordem crescente, o valor de $p_i - \Phi_i$ aumenta até a inclusão do h-ésimo elemento.que corresponde a \@ref(eq:DiscrepanciaMaximaDefinicao).

Considerando \@ref(eq:DiscrepanciaMaximaDefinicao), \@ref(eq:ProporcaoDaPopulacao) e \@ref(eq:ProporcaoDaRendaAcumulada) chaga-se em

\[
  D = \dfrac{h}{n} - \dfrac{1}{n\mu}\sum_{i=1}^{h}X_i
\]
que depois de algumas manobras algébricas torna-se

\[
  D = \dfrac{1}{n\mu}\sum_{i=1}^{h}(\mu - X_i)
(\#eq:DiscrepanciaMaximaEmTermosDeXi)
\]
Na parte de estatística descritiva foi apresentado a medida de dispersão desvio absoluto médio

\[
  \delta = \dfrac{1}{n}\sum_{i=1}^{n}|X_i - \mu|
\]
e considerando que
\[
  \delta = \dfrac{1}{n}\left[ -\sum_{i=1}^{h}\left(X_i - \mu\right) + \sum_{i=h+1}^{n}\left(X_i - \mu\right)\right]
\]
e que
\[
  \sum_{i=h+1}^{n}\left(X_i - \mu\right) = -\sum_{i=1}^{h}\left(X_i - \mu\right).
\]
Portanto
\[
\delta = \dfrac{2}{n}\sum_{i=h+1}^{n}\left(X_i - \mu\right) = \dfrac{2}{n}\sum_{i=1}^{h}\left(\mu - X_i \right).
(\#eq:DesvioAbsolutoMedioEquivalentes)
\]
Comparando \@ref(eq:DesvioAbsolutoMedioEquivalentes) e \@ref(eq:DiscrepanciaMaximaEmTermosDeXi) obtém-se

\[
D = \dfrac{\delta}{2\mu}.
(\#eq:DiscrepanciaMaximaFinal)
\]
Se o Desvio Absoluto Médio, $\delta$, é uma medida de dispersão da distribuição, a fórmula \@ref(eq:DiscrepanciaMaximaFinal) mostra que discrepância máxima, da mesma forma que o índice de Gini, é uma medida de dispersão relativa.
Retomando o exemplo numérico da tabela \@ref(tab:DadosdoExemploNumericoParaGini), é possível obter o valor da sua discrepância máxima através de \@ref(eq:DiscrepanciaMaximaDefinicao).

\[
D = p_h - \Phi_h = 0,625 - 0,180 = 0,445.
\]
O mesmo resultado poderia ser obtido através da fórmula \@ref(eq:DiscrepanciaMaximaFinal). Para isso é necessário calcular o desvio absoluto médio, $\delta$, para os valores de $X_i$ do exemplo numérico. Ou seja,

```{r DesvioAbsolutoMedio, echo=TRUE}
somadesvioabsolutomedioxi <- sum(abs(xi - ximedio))
somadesvioabsolutomedioxi

desvioabsolutomedioxi <- (length(xi))^(-1)*sum(abs(xi - ximedio))
desvioabsolutomedioxi
```

\[
\delta = \dfrac{1}{n}\sum_{i=1}^{n}|X_i - \mu| = \dfrac{1}{`r obs`}\times `r somadesvioabsolutomedioxi` = `r desvioabsolutomedioxi`.
\]
Portanto,

```{r DiscrepanciaMaxima, echo=TRUE}
discrepanciamaximaxi <- desvioabsolutomedioxi/(2*ximedio)
discrepanciamaximaxi
```

\[
  D = \dfrac{\delta}{2\mu} = \dfrac{`r desvioabsolutomedioxi`}{2 \times `r ximedio`} = `r discrepanciamaximaxi`.
\]

## Redundância e Índice de Theil

### Teoria da Informação

Para entender melhor as medidas de desigualdades de Theil, é necessário introduzir alguns conceitos da teoria da informação. 

Seja $x$, a probabilidadde de ocorrer o evento $E$.

- Para $x=1$, a mensagem **evento $E$ ocorreu** não tem nenhum conteúdo informativo. 

- Para $x \rightarrow 0$, ou seja, para valores muito pequenos de $x$, a mensagem **evento $E$ ocorreu** tem alto valor informativo.

A segunda situação seria, por exemplo, o caso de uma notícia que nos causas surpresa ou de um *furo* de imprensa. Quando $x$ tende a zero, o conteúdo informativo da mensagem **evento $E$ ocorreu** tende a infinito.

Matematicamente, o conteúdo informativo da mensagem que afirma que determinado evento ocorreu é dado por

\[
  h(x) = \log \dfrac{1}{x} = \log x^{-1} = - \log x
  (\#eq:ConteudoInformativo)
\]

De acordo com @Hoffmann2006, a escolha da função logarítmica é devido a propriedade de atividade do conteúdo informativo no caso de eventos independentes. Portanto, se $E_1$ e $E_2$ são dois eventos independentes com probabilidades $x_1$ e $x_2$, respectivamente, a probabilidade de que ambos ocorram é $x_1x_2$. O conteúdo informativo da mensagem de que ambos os eventos ocorreram é

\[
  h(x_1x_2) = \log \dfrac{1}{x_1x_2} = \log\dfrac{1}{x_1} + \log \dfrac{1}{x_2} = h(x_1) + h(x_2)
\]
Em teoria da informação, normalmente se utiliza logarítmos na base 2 ou logarítmos naturais. Desta forma:

- Logaritmos na base 2: o conteúdo informativo é medido em **bits**.

- Logaritmos naturais: o conteúdo informativo é medido em **nits**.

- 1 bit = 0,693 nit.

- 1 nit = 1,443 bit.

Generalizando o conceito de informação, é apresentando, na sequência, como se mede o conteúdo informativo de uma **mensagem sujeita a erro**, ou **mensagem incerta**.

Para isso, admita-se que a a probabilidade de chover em um determinado dia, em certo local, estabelecida com base em séries históricas, seja $x_1 = 0,5$. Nesse caso o conteúdo da informação **chove** é de

\[
  h(x_1) = \log\dfrac{1}{0,5} =\log 2^1 = 1~\text{bit}
\]
Suponha agora que uma previsão de tempo estabeleceu que iria chover. Suponha, também, que, com base nos resultados anteriores de tais previsões, probabilidade de que realmente shova passa a ser $y_1 = 0,68$. De acordo com as novas suposições, o conteúdo da informação **chove** é

\[
  h(y_1) = \log\dfrac{1}{o,68} + 0,5564~\text{bit}
\]

O conteúdo informativo da previsão é

\[
  h(x_1) - h(y_1) = \log\dfrac{1}{x_1} - \log\dfrac{1}{y_1} =  1 - 0,5564 = 0,4436~\text{bit}
\]
ou
\[
  h(x_1) - h(y_1) = \log\dfrac{1}{x_1} - \log\dfrac{1}{y_1} = \log\dfrac{1}{x_1} + \log \left(\dfrac{1}{y_1}\right)^{-1} = \log\dfrac{y_1}{x_1} = \log\left(\dfrac{0,50}{0,68}\right)  = 0,4436~\text{bit}.
\]
Ou seja, o conteúdo informativo **chove**, com base na probabilidade $x_i$ nos dados históricos e na probabilidade $y_i$ do histórico de previsões, é de 0,4436 bit.

Generalizando, o coanteúdo informativo de uma mensagem sujeita a erro ou mensagem incerta, como é o caso da previsão, é dado por

\[
  \log \dfrac{y}{x}
  (\#eq:ConteudoInformativoGeral)
\]
onde 

- $x$ é a probabilidade *ex-ante* ou a probabilidade de que o evento ocorra antes de recebida a mensagem;

- $y$ é a probabilidade *ex-post* ou a probabilidade de que oevento ocorra uma vez recebida a mensagem.

Na sequência é apreseantado o conceito de *entropia*.

**Entropia de uma distribuição $H(x)$**

Seja o universo de $n$ possíveis eventos $E_i$, para $i=1,\ldots ,n$, mutuamente exclusivos aos quais associa-se as probabilidades $x_i$. Sabe-se que

\[
  \sum_{i}^{n} x_i = 1.
\]

A informação esperada de uma mensagem certa, ou seja, a esperança matemática do conteúdo informativo da mensagem **ocorreu $E_i$**, também denominada entropia da distribuição, é 

\[
  H(x) = E[h(x_i)] = \sum_{i=1}^{n} x_i h(x_i) = \sum_{i=1}^{n}x_i \log\dfrac{1}{x_i} = - \sum_{i=1}^{n}x_i \log x_i
  (\#eq:InformacaoEsperadaDeUmaMensagemCerta)
\]

Para o caso particular de $x_i= 0$, adota-se a definição
\[
 x\log x = 0,~~\text{se}~x = 0
 (\#eq:CasoParticularxiIgualA0)
\]
uma vez que
\[
  \lim_{x\rightarrow 0}(x\log x) = 0
\]
Para $0 < x_i \leq 1$ se tem

\[
\dfrac{1}{x_i}\geq 1
\]

e

\[
\log \dfrac{1}{x_i} \geq 0.
\]
Conclui-se que
\[
H(x) = \sum_{i=1}^{n} x_i \log \dfrac{1}{x_i} = - \sum_{i=1}^{n} x_i \log x_i \geq 0 
\]

**Valor mínimo de $H(x)$**

O valor mínimo de $H(x)$ ocorre quando uma das probabilidades é 1 e as demais, consequentemente, são nulas. Nesse caso $H(x) = 0$. Ou seja, na somatória há um único $x_i=1$ e o restante $x_i = 0$. Portanto,

- quando $x=0$
  \[
    x \log x = 0
  \]
  de acordo com \@ref(eq:CasoParticularxiIgualA0);

- quando $x=1$ se tem $\log 1 = 0$ e também
  \[
    x \log x = 0.
  \]

Assim o valor mínimo do valor esperado do conteúdo informativo $H(x)$ é

\[
H(x) = - \sum_{i=1}^{n}x_i \log x_i = 0
\]

**Valor Máximo de $H(x)$**

Para encontrar o valor máximo de $H(x)$ sujeito a condição de que $\sum x_i = 1$, utiliza-se o método do multiplicador de Lagrange, escrevendo a seguinte função

\[
  \max H(x) = -\sum_{i=1}^{n}x_i \log x_i
\]
sujeito a
\[
  \sum_{i=1}^{n} x_i = 1
\]
então
\[
  \mathcal{L} = -\sum_{i=1}^{n}x_i \log x_i - \lambda\left( \sum_{i=1}^{n} x_i  - 1 \right)
  (\#eq:LagrangeanoDeHx)
\]
Igualando a zero as derivadas parciais de \@ref(eq:LagrangeanoDeHx) em relação a $x_i$ e admitindo-se que se usa os logaritmos naturais, se tem:

\[
  \log x_i = -(1 + \lambda),~~para~i=1,\ldots ,n
\]
sendo que
\[
  x_i = e^{-(1+\lambda)} = \dfrac{1}{e^{(1+\lambda)}}.
\]
O valor máximo de $H(x)$ acontece quando todos os valores de $x_i$, ou seja, todos as probabilidades são iguais entre si e, portanto, igual a $\dfrac{1}{n}$. Nesse caso,

\[
  H(x) = \sum_{i=1}^{n} x_i \log \dfrac{1}{x_i} = \sum_{i=1}^{n} \dfrac{1}{n} \log n = n \dfrac{1}{n}\log n = \log n 
\]

Resumindo, o valor esperado da informação ou a entropia da distribuição $H(x)$ varia entre 0 e $\log n$. Ou seja,

\[
  0\leq H(x) \leq \log n.
  (\#eq:IntervaloDeVariacaoDeHx)
\]

A entropia da distribuíção é máxima, ou seja, há um máximo de incerteza a respeito do que pode ocorrer, quando todos os possíveis eventos são igualmente prováveis, ou seja, quando há um máximo de *desordem* no sistema.

**Informação de uma mensagem incerta**

Finalmente é apresentado o conceito de informação de uma mensagem incerta. Dado o universo de $n$ possíveis eventos $E_i$, mutuamente exclusivos, com probabilidades $x_i$, para $i=1, \ldots, n$, considera-se uma mensagem incerta que poderia ser uma previsão ou uma mensagem duvidosa, que transforma as probabilidades *a priori* $x_i$ em probabilidade *a posteori* $y_i$, onde $y_i$ é a probabilidade de ocorrência do evento $E_i$ depois de recebido a mensagem. Lembrando
\@ref(eq:ConteudoInformativoGeral), verifica-se que a esperança matemática do conteúdo informativo da mensagem é

\[
I(y:x) = \sum_{i=1}^{n} y_i \log\dfrac{y_i}{x_i}
(\#eq:InformacaoDeUmaMensagemIncerta)
\]

A definição \@ref(eq:ConteudoInformativo), do conteúdo informativo de uma mensagem certa, é somente um caso especial de \@ref(eq:InformacaoDeUmaMensagemIncerta), eem que uma probabilidade *a posteriori* é igual a um  e todas as outras são iguais a zero,  ou seja, $y_j = 1$ e $y_i = 0$ para todo $i\neq j$. 

### Índice T de Theil

### Índice de L de Theil

## Variância dos Logaritmos


