# Distribuição de variáveis aleátórias conjunta

**Probabilidade conjunta** é a probabilidade que se refere a duas ou mais variáveis aleatórias simultaneamente.

A distribuição de probabilidade de um vetor $(X,Y)$ com duas variáveis, por exemplo,m seria o caso bidimensional. Como o material sobre este assunto é baseado em @Sartoris2013, a apresentação da distribuição de variáveis aleatórias conjuntas será o caso bidimensional.

As variáveis da distribuição de probabilidade conjunta podem ser discretas ou contínuas.

## Distribuição de probabilidade conjunta de variáveis aleatórias discretas

Com base em @Sartoris2013, é apresentado o assunto da seção através da apresentação de um exemplo numérico prático.

Seja um time de volei que vai dispoutar um campeonato muito equilibrado, em que a probabilidade de ganhar ou perder uma partida é de 0,5. O técnico pede ao estatístico da equipe que faça uma análise das probabilidades das três primeiras partidas consideradas vitais para o restante do campeonato. Em particular, a vitória na primeira partida é considerada decisiva pela comissão técnica.

O estátistico define duas variáveis, $X$ e $Y$, sendo que

- $X$ é o número de vitórias obtidas nos três primeiros jogos e;

- $Y$ é igual a 1, caso ocorra vitória no primeiro jogo e zero, caso ocorra o contrário.

Por enquanto considera-se que $X$ e $Y$ são variáveis independentes.

Como são três jogos com dois resultados possíveis, vitória ou derrota com 0,5 de probabilidade cada um, existem oito possibilidades entre os três primeiros jogos em análise. Na tabela \@ref(tab:ResultadosProvaveisEmTresPartidas) abaixo é apresentado os valores de $X$ e $Y$ de acordo com os resultados possíveis.

Table: (\#tab:ResultadosProvaveisEmTresPartidas) Resultados prováveis em três partidas, considerando vitória (V) ou derrota(D) como resultado possível de cada partida com 0,5 de probabilidade

----------------------------------------------------------------------------------
        resultados                   X                           Y
        possíveis
 ------------------------ -------------------------- ----------------------------
          VVV                         3                           1

          VVD                         2                           1

          VDV                         2                           1

          VDD                         1                           1

          DVV                         2                           0

          DDV                         1                           0

          DVD                         1                           0

          DDD                         0                           0
----------------------------------------------------------------------------------
Fonte: @Sartoris2013.

Onde o resultado possível nos três primeiros jogos definido como VDV significa que o time teve vitória na primeira e na terceira partidas e derrota na segunda partida. Esse mesmo resultado VDV define que $X=2$ e $Y=1$ lembrando que $X$ é o número de vitórias entre as três partidas e $Y$ é igual a 1 se o time conseguiu vitória na primeira partida e zero se não conseguiu ganhar a primeira partida.

Na sequência o estatístico constrói uma tabela que apresenta as probabilidades conjuntas de $x$ e $Y$ cujo preenchimento é feito com base na tabela \@ref(tab:ProbabilidadesConjuntasDeXeY)

Table: (\#tab:ProbabilidadesConjuntasDeXeY) Probabilidades conjuntas de $X$ e $Y$

-------------------------------------------------------
              X=0        X=1        X=2        X=3
 --------- ---------- ---------- ---------- ----------
  **Y=0**     1/8        2/8        1/8         0

  **Y=1**      0         1/8        2/8        1/8
-------------------------------------------------------

Com base na tabela \@ref(tab:ProbabilidadesConjuntasDeXeY) é possível obter a probabilidade para um resultado com duas vitórias sendo que uma das duas vitórias foi na primeira partida:

\[
  P(X=2~\text{ e }~Y=1) = 2/8
\]
Ou seja em oito resultados possíveis há duas combinações possíveis com resultado.

Veja que se o time ganha as três partidas $X=3$, não é possível que $Y=0$ e por isso

\[
  P(X=3~\text{ e }~Y=0 ) = 0
\]

O inverso também é válido. Ou seja, se o time não ganhou nenhuma das três partidas, não é possivel que $Y=1$ e por isso

\[
  P(X=0~\text{ e }~Y=1) = 0
\]

Ainda com base na tabela \@ref(tab:ProbabilidadesConjuntasDeXeY) é possível obter probabilidades só para valores de $X$ e probabilidades só para valores de $Y$. Ou seja, para obter a probabilidade de $X=1$ é ncessário somar todas as probabilidades conjuntas que tem $X=1$ 
\[
  P(X = 1) = P(X=1~\text{ e }~Y=0) + P(X=1~\text{ e }~Y=1) = 2/8 + 1/8 = 3/8.
\]
Na tabela \@ref(tab:ProbabilidadesConjuntasDeXeY), $P(X = 1)$ é obtida somando os valores da coluna para $X=1$.
Também é possível obter o valor da probabilidade de $Y=1$ que é simplesmente a soma de todos as probabilidades conjuntas que tem $Y=1$
\[
  P(Y=1) = P(X=0~\text{ e }~Y=1) + P(X=1~\text{ e }~Y=1) +P(X=2~\text{ e }~Y=1) + P(X=3~\text{ e }~Y=1)
\]
ou seja,
\[
  P(Y=1) = 0 + 1/8 +2/8 + 1/8 = 1/2
\]
Na tabela \@ref(tab:ProbabilidadesConjuntasDeXeY), $P(Y=1)$ é obtida somando os valores da linha para $Y=1$.
Assim, usando este raciocínio, é possível agregar mais uma linha e mais uma coluna com as probabilidades marginais de $X$ e de $Y$. As probabilidades marginais de $X$ são as somas de cada uma das colunas da tabela \@ref(tab:ProbabilidadesConjuntasDeXeY). As  probabilidades marginais de $Y$ são as somas de cada uma das linhas da tabela \@ref(tab:ProbabilidadesConjuntasDeXeY). Desta forma se obtém a tabela \@ref(tab:ProbabilidadesMarginaisDeXeY).

Table: (\#tab:ProbabilidadesMarginaisDeXeY) Probabilidades marginais de $X$ e $Y$

------------------------------------------------------------------
              X=0        X=1        X=2        X=3        P(Y)
 --------- ---------- ---------- ---------- ---------- ----------
  **Y=0**     1/8        2/8        1/8         0         **1/2**

  **Y=1**      0         1/8        2/8        1/8        **1/2**
  
  **P(X)**  **1/8**     **3/8**   **3/8**     **1/8**      **1**
------------------------------------------------------------------

Com base na tabela \@ref(tab:ProbabilidadesMarginaisDeXeY) é possível calcular a probabilidade condicional, embora não possa ser obtida diretamente da fonte.

Suponha a seguinte pergunta com base neste exemplo numérico prático: qual é probabilidade de time ganhar apenas uma partida entre as três dado que essa partida ocorre na primeira partida? Em notação matemática seria

\[
  P(X=1|Y=1) = \text{??}
\]

Lembrando das aulas de teoria da probabilidade, a probabilidade condicional e dada da seguinte forma:

\[
  P(X=x|Y=y) = \dfrac{P (X=x~\cap~Y=y)}{P(Y=y)}
\]

onde $P (X=x~\cap~Y=y)$ é a probabilidade conjunta entre $X=x$ e $Y=y$ e $P(Y=y)$ é a probabilidade marginal de $Y=y$.

Assim, podemos calcular a probabilidade condicional $P(X=1|Y=1)$

\[
  P(X=1|Y=1) = \dfrac{P (X=1~\cap~Y=1)}{P(Y=1)} = \dfrac{1/8}{1/2} = 1/4
\]

Dado que $Y=1$, só existe quatro possibilidades para essa situação, dos quais apenas uma situação tem $X=1$.

Note que o contrário também é possível obter. Ou seja considere a probabilidade condicional da seguinte forma:

\[
  P(Y=y|X=x) = \dfrac{P (Y=y~\cap~X=x)}{P(X=x)}.
\]

Com base no exemplo do time de volei, qual é probabilidade condicional de que o time não vença na primeira partida dado que o time ganhe duas entre as três partidas?

\[
  P(Y=0|X=2) = \dfrac{P (Y=0~\cap~X=2)}{P(X=2)}.
\]
Consultando a tabela \@ref(tab:ProbabilidadesMarginaisDeXeY) se tem

\[
  P(Y=0|X=2) = \dfrac{P (Y=0~\cap~X=2)}{P(X=2)} = \dfrac{1/8}{3/8} = 1/3
\]

Agora sabendo calcular a probabilidade condicional é possível verificar se as variáveis são independentes ou não. Para isso toma-se as situações de probabilidade conjunta igual a zero na tabela \@ref(tab:ProbabilidadesMarginaisDeXeY). Note que se o time ganha as três partidas, não há possbilidade da variável $Y$ assumir o valor 0. Veja o outro valor zero. Quando o time não ganha nenhuma das três primeiras partidas não é possível a variável $Y$ assumir valor igual a 1. A variável $Y$ sendo igual a 1 necessariamente o time tem que ter ganho a primeira partida.Por isso as variáveis $X$ e $Y$ do exemplo do time de volei não são independentes.

Então uma forma de verificar se as variáveis são independentes ou não é verificar se a probabilidade condicional é igual a probabilidade marginal. Ou seja,

\[
P(X=x|Y=y) = P(X=x)
\]
ou
\[
P(Y=y|X=x) = P(Y=y)
\]
Caso as probabilidades condicionais não sejam iguais a sua respectiva probabilidade marginal, então as duas variáveis $X$ e $Y$ não são independentes. Com base na tabela \@ref(tab:ProbabilidadesMarginaisDeXeY), toma-se, por exemplo,
a probabilidade conjunta para $X=1$ e $Y=1$
\[
  P(X=1|Y=1) =1/4
\]
e a probabilidade marginal $X=1$
\[
  p(X=1) = 3/8
\]
são diferentes. Portanto $X$ e $Y$ não são independentes. Basta somente um par de valores de $X$ e $Y$ apresentar essa diferença para poder concluir que as variáveis são dependentes uma da outra. Para verificar se as variáveis são independentes, é necessário verificar se todos o pares possíveis tem probabilidade condicional igual a probabilidade incondicional. Note que a probabilidade marginal é denominada também de probabilidade incondicional.

Ou seja,  basta somente uma situação com

\[
  P(X=x | Y=y) \neq P(X=x)
\]

para que $X$ e $Y$ seja dependentes.

### Covariância e correlação no contexto da distribuição de probabilidade conjunta

O cálculo do valor esperado bem como da variância de variáveis distribuídas conjutamente não é problema pois é possível obter as probabilidades marginais facilmente a partir das probabilidades conjuntas. O que há de novo, mas nem tanto, é sobre o cálculo da covariância e da correlação, que é apresentado na forma de exemplo numérico a seguir.

**Exemplo numérico sobre covariância e correlação para a distribuição conjunta**

Exemplo 5.1.1 da página 112 do @Sartoris2013. Calcule com base nos dados do exemplo numérico sobre o time de volei:

- o valor esperado de $X$ e $Y$;
- as variâncias de $X$ e $Y$;
- a covariância entre $X$ e $Y$;
- a correlação entre $X$ e $Y$.

Para calcular $E(X)$ utiliza-se as probabilidades marginais de $X$ que estão na tabela \@ref(tab:ProbabilidadesMarginaisDeXeY)

\[
E(X) = \sum_{i=1}^{n}P(X_i)X_i
\]

\[
E(X) =  P(X_1)\times X_1 + P(X_2)\times X_2 + P(X_3)\times X_3 + P(X_4)\times X_4
\]

Portanto,

\[
E(X) =  1/8\times 0 + 3/8\times 1  + 3/8\times 2 + 1/8\times 3 = 12/8 = 1,5
\]

A esperança matemática de $x$ do exemplo numérico é 1,5.

Para $Y$

\[
  E(Y) = \frac{1}{2}\times 0 + \frac{1}{2} \times 1 = 0,5
\]

Para calular a variância de $X$ usando a fórmula alternativa

\[
Var(X) = E(X^2) - [E(X)]^2
\]

Assim só está faltando calcular a esperança do quadrdado de $X$

\[
E(X^2) = \sum_{i=1}^{n} P(X_i) \times X_i^2 = P(X_1)\times X_1^{2} + \ldots + P(X_n)\times X_{n}^{2}
\]

Protanto,

\[
E(X^2) = \frac{1}{8}\times 0^{2} + \frac{3}{8} \times 1^2 + \frac{3}{8} \times 2^{2} + \frac{1}{8} \times 3^2 = \frac{24}{8} = 3
\]
Com $E(X)$ e $E(X^2)$

\[
  Var(X) = E(X^2) - [E(X)]^2 = 3 - (1,5)^2 = 3 - 2,25 = 0,75.
\]

Para a variância de $Y$ é necessário calcular $E(Y^2)$

\[
  E(Y^2) = \frac{1}{2}\times 0^2 + \frac{1}{2} \times 1^2 = 0,5
\]

Assim,

\[
 Var(Y) = E(Y^2) - [E(Y )]^2 = 0,5 - (0,5)^2 = 0,5 - 0,25 = 0,25
\]

Para calcular a covariancia entre $X$ e $Y$, com base na fórmula alternativa,
\[
  Cov(XY) = E(XY) - E(X)E(Y)
\]

é necessário calcular o produto entre $X$ e $Y$ que segue na tabela \@ref(tab:ProdutoEntreXeY).

Table: (\#tab:ProdutoEntreXeY) Produto entre $X$ e $Y$

-------------------------------------------------
        X               Y               XY
 --------------- --------------- ---------------
        3               1               3

        2               1               2

        2               1               2

        1               1               1

        2               0               0

        1               0               0

        1               0               0

        0               0               0
-------------------------------------------------

Com base nos resultados de $XY$ apresentados na tabela \@ref(tab:ProdutoEntreXeY), é possível obter as seguintes probabilidades

\[
  P(XY=0) = \frac{4}{8}
\]

\[
  P(XY = 1) = \frac{1}{8}
\]

\[
  P(XY = 2) = \frac{2}{8}
\]

\[
  P(XY = 3) = \frac{1}{8}.
\]

Assim

\[
  E(XY) = \sum_{i=1}^{n} P(X_iY_i) \times XY
\]

\[
  E(XY) = \frac{4}{8} \times 0 + \frac{1}{8}\times 1 + \frac{2}{8} \times 2 + \frac{1}{8} \times 3 = \frac{8}{8} = 1
\]

como já se tem calculado $E(X)$ e $E(Y)$

\[
  Cov(XY) = E(XY) - E(X)E(Y) = 1 - (1,5)(0,5) = 1 - 0,75 = 0,25
\]

Para o cálculo da correlação se tem todas as partes da sua fórmula calculadas

\[
  corr(XY) = \rho_{XY} = \dfrac{Cov(X,Y)}{\sqrt{Var(X) \times Var(Y)}} 
\]

Portanto

\[
  \rho_XY = \dfrac{0,25}{\sqrt{0,75 \times 0,25}} \cong 0,5774
\]

### Esperança condicionada

A esperança condicionada é similar a esperança marginal ou incondicional sendo que as probabilidades associadas a variável em questão é a probabilidade condicionada que precisa ser previamente calculada, dado que é necessário ter a probabiliade conjunta e a probabilidade marginal ou incondicional para o seu cálculo. Ou seja se é probabilidade de $X$ dado $Y$

\[
  P(X=x|Y=y) = \dfrac{P (X=x~\cap~Y=y)}{P(Y=y)}
\]

para poder calcular a esperança condicionada de $X$ dado $Y$

\[
  E(X_i|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i.
\]

**Exemplo numérico sobre Esperança condicional**

Exemplo 5.1.2 da página 113 do @Sartoris2013. Seja as variáveis aleatórias $X$ e $Y$ definidas no exemplo sobre o time de volei, determine $E(X|Y=0)$.

**Resposta**:

Para o cálculo da esperança condicionada são necessárias as probabilidades condicionais para todos os valores de $X$. Pois

\[
  E(X|Y=0) = \sum_{i=1}^{n} P(X_i|Y=0) \times X_i
\]
As probabilidades condicionais são
\[
  P((X=0|Y=0) = \dfrac{P(X=0~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]

\[
  P((X=1|Y=0) = \dfrac{P(X=1~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{2}{8}}{\dfrac{1}{2}}= \dfrac{1}{2}
\]

\[
  P((X=2|Y=0) = \dfrac{P(X=2~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]

\[
  P((X=3|Y=0) = \dfrac{P(X=3~\text{e}~Y=0)}{P(Y=0)}= \dfrac{0}{\dfrac{1}{2}}= 0
\]

Com essas probabilidades condicionais calcula-se a esperança de $X$ condicionada a $Y=0$

\[
  E(X|Y=0) = \frac{1}{4}\times 0 + \frac{1}{2} \times 1 + \frac{1}{4}\times 2 + 0 \times 3 = 1
\]
Portanto a $E(X|Y=0) = 1$.

### Lei das Expectativas Iteradas

A lei das expectativas iteradas diz que o valor esperados das esperanças condicionais é igual a esperança incondicional. Ou seja,

\[
  E[E(X|Y)] = E(X)
  (\#eq:ExpectativasIteradas)
\]

**Exemplo sobre a Lei das Expectativas Iteradas**

O Exemplo 5.1.3 da página 114 do @Sartoris2013 tem o objetivo de aplicar a lei das expectativas iteradas através de \@ref(eq:ExpectativasIteradas). Seja as variáveis $X$ e $Y$ do exemplo sobre o time de volei, determine $E[E(X|Y)]$.

**Resposta**:

Note que o cálculo da esperança das esperanças condicionais é necessário os todos as esperanças condicionais de $X$ e as respectivas probabilidades de $Y$. Como já foi calculado $E(X|Y=0)$ no exemplo numérico anterior, fica faltando $E(X|Y=1)$, uma vez que os valores de $Y$ são zero e um. Ou seja,

Para o cálculo da esperança condicionada de #$X$ dado que $Y=1$ são necessárias as probabilidades condicionais para todos os valores de $X$. Pois

\[
  E(X|Y=1) = \sum_{i=1}^{n} P(X_i|Y=1) \times X_i
\]
sendo que 

\[
  P(X|Y=1) = \dfrac{P(X~\text{e}~Y=0)}{P(Y=0)}.
\]

As probabilidades condicionais são
\[
  P((X=0|Y=1) = \dfrac{P(X=0~\text{e}~Y=1)}{P(Y=1)}= \dfrac{0}{\dfrac{1}{2}}= 0
\]

\[
  P((X=1|Y=1) = \dfrac{P(X=1~\text{e}~Y=1)}{P(Y=1)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]

\[
  P((X=2|Y=1) = \dfrac{P(X=2~\text{e}~Y=1)}{P(Y=1)}= \dfrac{\dfrac{2}{8}}{\dfrac{1}{2}}= \dfrac{1}{2}
\]

\[
  P((X=3|Y=1) = \dfrac{P(X=3~\text{e}~Y=1)}{P(Y=1)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]

Com essas probabilidades condicionais calcula-se a esperança de $X$ condicionada a $Y=1$

\[
  E(X|Y=1) = 0 + \frac{1}{4} \times 1 + \frac{1}{2}\times 2 + \dfrac{1}{3} \times 3 = 2
\]
Portanto a $E(X|Y=1) = 2$.

O valor de $E[E(X|Y)]$ é calculado da seguinte forma

\[
  E[E(X|Y)] = \sum_{j=1}^{k} P(Y_j)\times E(X|Y_j)
\]
onde $j=1,\ldots,k$. Assim sendo, para o exemplo numérico fica

\[
  E[E(X|Y)] = P(Y=0) \times E(X|Y=0) + P(Y=1) \times E(X|Y=1)
\]
colocando os valores calculados
\[
  E[E(X|Y)] = \dfrac{1}{2} \times 1 + \frac{1}{2} \times 2 = 1,5 
\]
Note que $E(X)$ calculando anteriormente é, de fato, 1,5. Portanto confirma-se através do exemplo numérico que

\[
  E[E(X|Y)] = E(X).
\]

### Variância condicionada

A variância condicional como o próprio nome diz é a variância de uma variável condicionada ao valor de uma outra variável. Por isso o seu cálculo necessíta a probabilidade condicional e a esperança condicionada. Neste caso, além da esperança condicional da variável em si, é necessário calcular a esperança condicional da variável elevada ao quadrado. Ou seja,

\[
  P(X=x|Y=y) = \dfrac{P (X=x~\cap~Y=y)}{P(Y=y)}
\]

para calcular a esperança condicionada de $X$ dado $Y$

\[
  E(X_i|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i.
\]

e a esperança condicionada de $X^2$ dado $Y$

\[
  E(X_i^2|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i^2.
\]
para então calcular

\[
  Var(X|Y=c) = E(X^2|Y=c) - [E(X|Y=c)]^2.
\]

**Exemplo sobre a variância condicionada**

Exemplo 5.1.4 da página 114 do @Sartoris2013. Com base nas variáveis do exemplo do time de volei, calcule $Var(Y|X=1)$.

**Resposta**:

É necessário calcular $P(Y=0|X=1)$ e $P(Y=1|X=1)$

\[
  P(Y=0|X=1) = \dfrac{P(Y=0~\cap~X=1)}{P(X=1)} = \dfrac{\dfrac{2}{8}}{\dfrac{3}{8}}=\dfrac{2}{3}
\]
e
\[
  P(Y=1|X=1) = \dfrac{P(Y=1~\cap~X=1)}{P(X=1)} = \dfrac{\dfrac{1}{8}}{\dfrac{3}{8}}=\dfrac{1}{3}.
\]
Assim
\[
  E(Y|X=1) = P(Y=0|X=1) \times 0 + P(Y=1|X=1) \times 1
\]

\[
  E(Y|X=1) = \dfrac{2}{3} \times 0 + \dfrac{1}{3} \times 1 = \dfrac{1}{3}.
\]
Para $Y^2$
\[
  E(Y^2|X=1) = P(Y=0|X=1) \times 0^2 + P(Y=1|X=1) \times 1^2
\]

\[
  E(Y|X=1) = \dfrac{2}{3} \times 0^2 + \dfrac{1}{3} \times 1^2 = \dfrac{1}{3}.
\]

Portanto,

\[
  Var(Y|X=1) = E(Y^2|X=1) - [E(Y|X=1)]^2
\]

\[
  Var(Y|X=1) = \dfrac{1}{3} - [\dfrac{1}{3}]^2 
\]

\[
  Var(Y|X=1) = \dfrac{1}{3} - \dfrac{1}{9} = \dfrac{2}{9} 
\]

**Outro exemplo numérico sobre variância condicionada**

Exemplo 5.1.5 na página 114 do @Sartoris2013. Sejam as variáveis $X$ e $Y$ do exemplo numérico do time de volei. Calcule $Var(X|Y=0)$ e $Var(X|Y=1)$.

**Resposta**:

É necessário calcular

\[
  P(X=x|Y=y) = \dfrac{P (X=x~\cap~Y=y)}{P(Y=y)}
\]

para poder calcular a esperança condicionada de $X$ dado $Y$

\[
  E(X_i|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i.
\]

e a esperança condicionada de $X^2$ dado $Y$

\[
  E(X_i^2|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i^2.
\]
para então calcular

\[
  Var(X|Y=c) = E(X^2|Y=c) - [E(X|Y=c)]^2.
\]
Já estão calculados

\[
  P((X=0|Y=0) = \dfrac{P(X=0~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]

\[
  P((X=1|Y=0) = \dfrac{P(X=1~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{2}{8}}{\dfrac{1}{2}}= \dfrac{1}{2}
\]

\[
  P((X=2|Y=0) = \dfrac{P(X=2~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]

\[
  P((X=3|Y=0) = \dfrac{P(X=3~\text{e}~Y=0)}{P(Y=0)}= \dfrac{0}{\dfrac{1}{2}}= 0
\]
 e 
\[
  P((X=0|Y=1) = \dfrac{P(X=0~\text{e}~Y=1)}{P(Y=1)}= \dfrac{0}{\dfrac{1}{2}}= 0
\]

\[
  P((X=1|Y=1) = \dfrac{P(X=1~\text{e}~Y=1)}{P(Y=1)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]

\[
  P((X=2|Y=1) = \dfrac{P(X=2~\text{e}~Y=1)}{P(Y=1)} \dfrac{\dfrac{2}{8}}{\dfrac{1}{2}}= \dfrac{1}{2}
\]

\[
  P((X=3|Y=1) = \dfrac{P(X=3~\text{e}~Y=1)}{P(Y=1)} \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}.
\]

Também já estão calculados

\[
  E(X|Y=0) = \frac{1}{4}\times 0 + \frac{1}{2} \times 1 + \frac{1}{4}\times 2 + 0 \times 3 = 1
\]
e
\[
  E(X|Y=1) = 0 + \frac{1}{4} \times 1 + \frac{1}{2}\times 2 + \dfrac{1}{3} \times 3 = 2.
\]
Faltam ser calculadas as $E(X^2|Y=0)$ e $E(X^2|Y=1)$.

\begin{multline}
  E(X^2|Y=0) = P(X=0|Y=0) \times 0^2 + P(X=1|Y=0)\times 1^2 +\\
  P(X=2|Y=0) \times 2^2 + P(X=3|Y=0) \times 3^2
\end{multline}
\[
  E(X^2|Y=0) = \dfrac{1}{4} \times 0^2 + \dfrac{1}{2}\times 1^2 +
  \dfrac{1}{4} \times 2^2 + 0 \times 3^2 = 1,5.
\]
e 
\begin{multline}
  E(X^2|Y=1) = P(X=0|Y=1) \times 0^2 + P(X=1|Y=1)\times 1^2 +\\
  P(X=2|Y=1) \times 2^2 + P(X=3|Y=1) \times 3^2
\end{multline}
\[
  E(X^2|Y=1) = 0 \times 0^2 + \dfrac{1}{4}\times 1^2 +
  \dfrac{1}{2} \times 2^2 + \dfrac{1}{4} \times 3^2 = 4,5.
\]

Portanto, as variâncias condicionadas são

\[
  Var(X|Y=0) = E(X^2|Y=0) - [E(X|Y=0)]^2 = 1,5 - 1^2 = 0,5.
\]

\[
  Var(X|Y=1) = E(X^2|Y=1) - [E(X|Y=1)]^2 = 4,5 - 2^2 = 0,5.
\]
Note que a variância condicional é sempre ou quase sempre menor do que a variância incondicional, ou seja,

\[
  Var(X|Y) \leq Var(X)
\]
e
\[
  Var(Y|X) \leq Var(Y).
\]

Por outro lado, Esperança condicional pode ser menor ou maior ou igual a esperança incondicional. Ou seja,

\[
  E(X|Y) >=<E(X)
\]
e
\[
  E(Y|X) >=<E(Y)
\]

Para entender essas relações, toma-se o exemplo do time de volei. 

Se é garantido que o primeiro jogo vitória, ou seja, dado que $Y=1$, o número de vitórias esperado aumenta.Ao contrário, se o primeiro jogo é, com certeza, derrota, o número  de vitórias esperado diminui.  

No caso da variância, condicional ou não, é uma media de dispersão. O fato do resultado do primeiro jogo ser dado, seja o resultado qual for, diminui o núero de resultados possíveis. Por isso, a variância condicional ser quase sempre menor.

Se as variáveis $X$ e $Y$ forem independentes, isso significa

\[
  P(X|Y) = P(X)
\]
e
\[
  E(X|Y) = E(X)
\]
e
\[
  Var(X|Y) = Var(X).
\]
Obviamente, também

\[
  P(Y|X)= P(Y)
\]
e
\[
  E(Y|X) = E(Y)
\]
e
\[
  Var(Y|X) = Var(Y).
\]

### Decomposição da Variância

A decomposição da variância entrega uma relação interessante

\[
  Var(X) = Var[E(X|Y)] + E[Var(X|Y)]
\]

**Exemplo sobre a decomposição da variância**

Exemplo 5.1.6 da página 115 do @Sartoris2013. Tomando o exemplo do time de volei, calcule $E[Var(X|Y)]$ e $Var[E(X|Y)]$

**Resposta**:

\[
  E[Var(X|Y)] = Var(X|Y=0) \times P(Y=0) + Var(X|Y=1) \times P(Y=1)
\]

\[
  E[Var(X|Y)] = 0,5 \times 0,5 + 0,5 \times 0,5
\]

\[
  E[Var(X|Y)] = 0,5.
\]

No caso da $Var[E(X|Y)]$ é necessário calcular $E\{[E(X|Y)]^2\}$, pois

\[
  Var[E(X|Y)] = E\{[E(X|Y)]^2\} - \{E[E(X|Y)]\}^2
\]

Então,

\[
  E\{[E(X|Y)]^2\} = E[E(X|Y=0)]^2\times P(Y=0) + E[E(X|Y=1)]^2\times P(Y=1) 
\]

\[
  E\{[E(X|Y)]^2\} = 1^2\times 0,5 + 2^2\times 0,5 
\]

\[
  E\{[E(X|Y)]^2\} = 2,5 
\]
Portanto,

\[
  Var[E(X|Y)] = E\{[E(X|Y)]^2\} - \{E[E(X|Y)]\}^2 
\]

\[
  Var[E(X|Y)] = 2,5 - (1,5)^2 
\]

\[
  Var[E(X|Y)] = 2,5 - 2,25 
\]

\[
  Var[E(X|Y)] = 0,25
\]


## Distribuição de probabilidade conjunta de variáveis aleatórias contínuas

Se as variáveis aleatórias forem contínuas, o procedimento é similar a da situação com uma variável. Neste caso haverá duas integrais no caso de duas variáveis.

