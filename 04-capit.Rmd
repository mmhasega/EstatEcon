# Variável Aleatória Discreta

A associação de cada um dos valores de uma variável a uma probabilidade 
correspondente de ocorrer corresponde a uma **distribuição de 
probabilidade**.

Essa distribuição de probabilidade pode ser de uma variável aleatória discreta
ou de uma variável aleatória contínua. No capítulo 03 do @Sartoris2013 apresenta-se
a distribuições de probabilidade de variáveis aleatórias discretas. 

## Esperança matemática

Quando se calcula uma média do que **pode** acontecer com a variável,
baseada em sua distribuição de probabilidade, está obtendo-se um valor médio esperado.
Ou seja, a **esperança matemática**, ou, simplesmente, **esperança**.

A esperança de uma variável aleatória discreta $X$, denotada $E(X)$, é definida como

\[
  E(X) = X_1P(X_1) + X_2P(X_2) + \ldots + X_nP(X_n) = \sum_{i=1}^{n}X_iP(X_i)
\]

A probabilidade aqui tem o mesmo papel da frequência relativa.

Note que,

- quando se fala em frequência relativa, usualmente refere-se a 
  uma quantidade obtida.
- quando se fala em probabilidade, nos remete a ideia de proporções em que 
  a variável pode assumir determinado valor.

### Função de Probabilidade

$P(X)$ é a função que associa o valor de $X$ à sua probabilidade, que é chamada 
de **função de probabilidade**. É representada como $f(X)$. 
Desta forma pode-se escrever:

\[
E(X) = \sum_ {i=1}^{n}X_i f(X_i)~~para~i=1,\ldots,n.
\]

### Função distribuição acumulada

A função que fornece a probabilidade acumulada dado o valor de $X$ é a 
**função distribuição acumulada** ou, simplesmente, função distribuição, 
representada por $F(X)$.

\[
F(X_k) = \sum_{i=1}^{k} f(X_i)~~para~i=1, \ldots,n
\] 

**Exemplo numérico sobre Função de Probabilidade (Sartoris, 2013, pg.55)**

Este exemplo numérico bem básico é sobre probabilidade que está na página 55 de 
@Sartoris2013.
Num sorteio de números inteiros de 1 a 5, a probabilidade de um número ser sorteado é proporcional a esse número. Qual é a probabilidade de cada número ser sorteado?

**Resposta**: Se considerarmos que a $P(1)$ é igual a $1A$, onde $A$ é uma constante desconhecida, temos:

$P(1)=A$

$P(2)=2A$

$P(3)=3A$

$P(4)=4A$

$P(5)=5A$.

Sendo os eventos mutuamente exclusivos,a soma de todas as probabilidades tem de ser igual a 1. Portanto,

$P(1) + P(2) + P(3) + P(4) + P(5) = 1$

$A + 2A + 3A + 4A + 5A = 1$

$15A = 1$

$A = \dfrac{1}{15}$.

### Esperanças, Variâncias e Covariâncias

Note que

\begin{align}
  E[aX + b] &= aE(X) + b \\
  E[X + Y] &= E(X) + E(Y) \\
  Var(X) &= E[X - E(X)]^2 = E(X^2) - [E(X)]^2 \\
  Cov(X,Y) &= E[X - E(X)][Y - E(Y)] = E(XY) - E(X)E(Y)
\end{align}

**Exemplo Numérico sobre Esperança e Variância (Sartoris, 2013, p.56)**

Este exemplo numérico é o 3.1.2 do @Sartoris2013 que está na página 56.
Uma ação comprada por R\$10,00 pode assumir, após 30 dias, os seguintes valores:
R\$5,00 com 20\% de probabilidade; R\$10,00 com 30\% de probabilidade; R\$16,00 com 25\% de probabilidade ou R\$20,00 com 25\% de probabilidade. Determine o valor esperado da ação e sua variância.

**Resposta**: O valor esperado da ação é

\begin{align}
  E(X) &= 5 \times 0,2 + 10 \times 0,3 + 16 \times 0,25 + 20 \times 0,25 \\
  E(X) &= 1 + 3 + 4 + 5 = 13
\end{align}

omo o preço da ação foi de R\$ 10,00, o lucro médio esperado dessa ação é de R\$3,00.

Para calcular a variância pela forma alternativa, é necessário calcular somente $E(X^2)$ uma vez que $E(X)$ já foi calculado.

\begin{align}
  E(X^2) &= (5)^2 \times 0,2 + (10)^2 \times 0,3 + (16)^2 \times 0,25 + (20)^2 \times 0,25 \\
  E(X^2) &= 25 \times 0,2 + 100 \times 0,3 + 256 \times 0,25 + 400 \times 0,25 \\
  E(X^2) &= 5 + 30 + 64 + 100 \\
  E(X^2) &= 199.
\end{align}

Assim,

\begin{align}
  Var(X) &= E(X^2) - [E(X)]^2\\
  Var(X) &= 199 - 13^2 \\
  Var(X) &= 30.
\end{align}

Note que, ao medir a dispersão dos possíveis valores da ação, a variância é uma medida do risco da ação.

## Variável Aleatória Discreta

Quando os valores da variável são específicas, ou seja, não pode assumir qualquer valor dentro do conjunto dos números reais.

## Distribuição Uniforme

Na **distribuição uniforme** todos os elementos têm a mesma probabilidade de ocorrer.

Exemplo: obter um número de 1 a 6, lançando um dado não viciado. A probabilidade de obter qualquer um dos seis números é de $1/6$.

**Exemplo numérico sobre Distribuição Uniforme (Sartoris, 2013, p.57)**

Este exemplo numérico sobre distribuição uniforme está na página 57 de @Sartoris2013.

Joga-se um dado uma única vez. Qual o valor esperado do número obtido? E sua variância?

**Resposta**: O valor esperado é

\begin{align}
  E(X) &= 1 \times \dfrac{1}{6} + 2 \times \dfrac{1}{6} + 3\times \dfrac{1}{6} + 4\times \dfrac{1}{6} + 5\times \dfrac{1}{6} + 6\times \dfrac{1}{6}\\
  E(X) &= 3,5.
\end{align}

Para calcular a variância pela forma alternativa é necessário $E(X^2)$.

\begin{align}
  E(X^2) &= (1)^2\dfrac{1}{6} + (2)^2\dfrac{1}{6} + (3)^2\dfrac{1}{6} + (4)^2\dfrac{1}{6} + (5)^2\dfrac{1}{6} + (6)^2\dfrac{1}{6} \\
  E(X^2) &= 1\dfrac{1}{6} + 4\dfrac{1}{6} + 9\dfrac{1}{6} + 16\dfrac{1}{6} + 25\dfrac{1}{6} + 36\dfrac{1}{6} \\
  E(X^2) &=\dfrac{91}{6}.
\end{align}

Desta forma a variância é

\begin{align}
  Var(X) &= E(X^2) - [E(X)]^2\\
  Var(X) &= \dfrac{91}{6} - \left( \dfrac{21}{6} \right)^2\\
  Var(X) &= \dfrac{105}{36}\\
  Var(X) &\cong 2,92 
\end{align}

## Distribuição de Bernoulli

A **distribuição de Bernoulli** caracteriza-se pela existência de apenas dois eventos, mutuamente exclusivos, denominados **sucesso** e **fracasso**, num experimento que é realizado uma única vez.

Se a probabilidade de **sucesso** é $p$, a probabilidade de **fracasso** é $(1-p)$, uma vez que só existem esses dois eventos e eles são mutuamente exclusivos.

**Exemplos de distribuição de Bernoulli**

- **lançamento de uma moeda uma única vez**. Se o resultado cara é o sucesso, associado a uma probabilidade $p=1/2$, então o resultado coroa é o fracasso associado a uma probabilidade $(1-p)=1/2$.

- **lançamento de um dado uma única vez**. Se o número escolhido é três, então o resultado 3 é o sucesso, associado a uma probabilidade $p=1/6$ e qualquer um dos outros cinco números é o fracasso, associado aum probabilidade $(1-p) = 5/6$.

**Exemplo numérico sobre distribuição de Bernoulli (Sartoris, 2013, p.58)**

Este exemplo numérico sobre distribuição de Bernoulli está na página 58 de @Sartoris2013.

No caso da cara ou coroa, atribuindo o valor 1 para o sucesso e 0 para o fracasso, dtermine a média e a variância do resultado após uma jogada.

**Resposta**: A média é

\begin{align}
  E(X) &= 1 \times \dfrac{1}{2} + 0 \times \dfrac{1}{2}\\
  E(X) &= \dfrac{1}{2}\\
  E(X) &=0,5
\end{align}

E a variância

\begin{align}
  E(X^2) &= 1^2 \times \dfrac{1}{2} + 0^2 \times \dfrac{1}{2}\\
  E(X^2) &= \dfrac{1}{2}\\
  E(X^2) &= 0,5
\end{align}

\begin{align}
  Var &= E(X^2) - [E(X)]^2\\
  Var &= 0,5 - (0,5)^2\\
  Var &= 0,25.
\end{align}

**Outro exemplo numérico sobre distribuição de Bernoulli (Sartoris, 2013, p.59)**

No caso do dado, em que se aposta em um único número, atribuindo o valor 1 para o sucesso e 0 para o fracasso, determine a média e a variância do resultado após uma jogada.

**Resposta**: A média é

\begin{align}
  E(X) &= 1 \times \dfrac{1}{6} + 0 \times \dfrac{5}{6}\\
  E(X) &= \dfrac{1}{6}
\end{align}

E a variância

\begin{align}
  E(X^2) &= 1^2 \times \dfrac{1}{6} + 0^2 \times \dfrac{5}{6}\\
  E(X^2) &= \dfrac{1}{6}
\end{align}

\begin{align}
  Var &= E(X^2) - [E(X)]^2\\
  Var &= \dfrac{1}{6} - \left(\dfrac{1}{6}\right)^2\\
  Var &= \dfrac{5}{36}
\end{align}

**Média e Variância da Distribuição de Bernoulli**

Pelos exemplos numéricos apresentado, verifica-se que numa distribuição de Bernoulli:

\begin{align}
  E(X) &= p \\
  Var(X) &= p(1-p)
\end{align}

## Distribuição Binomial

A **distribuição Binomial** é a generalização da distribuição de Bernoulli. Ou seja,
há um sucesso com probabilidade $p$ e um fracasso com probabilidade $(1-p)$. Mas o número de experimentos ou jogadas pode ser qualquer um.

Retomemos o exemplo da cara ou coroa, mas agora com três jogadas ou experimentos.

Associa-se cara a uma letra $C$ e uma coroa a uma letra $K$ para facilitar a 
visualização.

| jogada 1 | jogada 2 | jogada 3 |
|:--------:|:--------:|:--------:|
| C | C | C |
| C | C | K |
| C | K | C |
| C | K | K |
| K | C | C |
| K | C | K |
| K | K | C |
| K | K | K |

Na primeira jogada só há dois resultados possíveis: cara ou coroa. Portanto

\begin{align*}
  P(C) &= p = 1/2 \\
  P(K) &= (1-p) = 1/2
\end{align*}

Na segunda jogada há quatro combinações para três resultados possíveis que são (cara, cara); (cara, coroa) e (coroa, coroa. Portanto

\begin{align*}
  P(C,C) &= pp = 1/4 \\
  P(C,K) + P(K,C) &= p(1-p) + (1-p)p = 2p(1-p) = 2/4\\
  P(K,K) &= (1-p)(1-p) = 1/4
\end{align*}

Na terceira jogada há oito combinações para quatro resultados possíveis que são (cara, cara,cara); (cara,cara,coroa); (cara,coroa, coroa) e (coroa, coroa, coroa). Portanto

\begin{align*}
  P(C,C,C) &= 1/8 \\
  P(C,C,K) + P(C,K,C) + P(K,C,C) &= 3/8\\
  P(K,K,C) + P(K,C,K) + P(C,K,K) &= 3/8\\
  P(K,K,K) &= 1/8
\end{align*}

Ou em detalhes:

\begin{equation*}
  P(3\text{ caras}) = ppp = 1/8
\end{equation*}
\begin{equation*}
  P(2\text{ caras}, 1\text{ coroa}) = pp(1-p) + p(1-p)p + (1-p)pp = 3pp(1-p) = 3/8
\end{equation*}
\begin{multline*}
  P(2\text{ coroas}, 1\text{ cara}) = (1-p)(1-p)p + (1-p)p(1-p) + p(1-p)(1-p)\\
  = 3(1-p)(1-p)p = 3/8
\end{multline*}
\begin{equation*}
  P(3\text{ coroas}) = (1-p)(1-p)(1-p) = 1/8
\end{equation*}

Ou seja,

\begin{align*}
  P( 3~\text{caras}) &= 1\times p \times p \times p\\
  P(2\text{ caras}, 1\text{ coroa}) &= 3 \times p \times p \times (1-p)\\
  P(2\text{ coroas}, 1\text{ cara}) &= 3  \times (1-p) \times (1-p) \times p\\
  P( 3~\text{coroas}) &= 1\times (1-p) \times (1-p) \times (1-p)
\end{align*}

usando o binômio de newton,

\begin{equation*}
  \binom{n}{k} = \frac{n!}{k!(n-k)!}
\end{equation*}

\begin{align*}
  P( 3~\text{caras}) &= \binom{3}{3} \times p \times p \times p\\
  P(2\text{ caras}, 1\text{ coroa}) &= \binom{3}{2} \times p \times p \times (1-p)\\
  P(2\text{ coroas}, 1\text{ cara}) &= \binom{3}{1} \times (1-p) \times (1-p) \times p\\
  P( 3~\text{coroas}) &= \binom{3}{0} \times (1-p) \times (1-p) \times (1-p)
\end{align*}

Generalizando, nos leva a função de probabilidade,

\begin{equation*}
  P(X=k) = \frac{n!}{k!(n-k)!} p^k (1-p)^{n-k}
\end{equation*}
onde

- $k$ é o número de sucessos;
- $n$ é o número de jogadas ou experimentos;
- $p$ é a probabilidade de sucesso;
- $(1-p)$ é a probabilidade de fracasso.

**O primeiro exemplo numérico de distribuição binomial**

 O primeiro exemplo numérico de distribuição binomial é o exemplo numérico 3.2.3.1 da página 62 do @Sartoris2013. Suponha um jogo de dados em que aposta em um único número. Determine as seguintes probabilidades:

 - em três jogadas, ganhar duas.

\begin{align*}
  P(X=2) &= \binom{3}{2} \times \left(\frac{1}{6}\right)^2\times \left(\frac{5}{6}\right)^{(3-2)}\\
  P(X=2) &= \frac{3!}{2!(3-2)!}\times \frac{1}{36} \times \frac{5}{6}\\
  P(X=2) &= 3 \times \frac{1}{36} \times \frac{5}{6}\\
  P(X=2) &= \frac{15}{216} = 0,0694
\end{align*}

 - em quatro jogadas, ganhar duas.

\begin{align*}
  P(X=2) &= \binom{4}{2} \times \left(\frac{1}{6}\right)^2\times \left(\frac{5}{6}\right)^{(4-2)}\\
  P(X=2) &= \frac{4!}{2!(4-2)!}\times \frac{1}{36} \times \frac{25}{36}\\
  P(X=2) &= 6 \times \frac{1}{36} \times \frac{25}{36}\\
  P(X=2) &= \frac{150}{1.296} = 0,1157
\end{align*}

- Em cinco jogadas, ganhar três.

\begin{align*}
  P(X=3) &= \binom{5}{3} \times \left(\frac{1}{6}\right)^3\times \left(\frac{5}{6}\right)^{(5-3)}\\
  P(X=3) &= \frac{5!}{3!(5-3)!}\times \frac{1}{216} \times \frac{25}{36}\\
  P(X=3) &= 10 \times \frac{1}{216} \times \frac{25}{36}\\
  P(X=3) &= \frac{250}{7.776} = 0,0321
\end{align*}

**Um segundo exemplo numérico de distribuição binomial**

O segundo exemplo numérico sobre distribuição binomial é da página 63 de @Sartoris2013. Calcule a média e a variância no jogo  de cara ou coroa, atribuindo valor um para cara e zero para coroa. 

Considerando uma ,duas e três jogadas.

- Para uma jogada, que é o caso particular da distribuição de Bernoulli.

\begin{equation*}
  E(X) = p = \frac{1}{2}
\end{equation*}
\begin{equation*}
  var(X) = p(1-p) = \frac{1}{2}\left(1  - \frac{1}{2} \right) = \frac{1}{4}
\end{equation*}

- Para duas jogadas: CC; CK; KC; KK. Ou seja,

\begin{equation*}
  E(X) = 2 \times \frac{1}{4} + 1 \times \frac{2}{4} + 0 \times \frac{1}{4} = \frac{4}{4} = 1
\end{equation*}

\begin{equation*}
  E(X^2) = 2^2\times \frac{1}{4} + 1^2 \times \frac{2}{4} + 0^2\times \frac{1}{4} = \frac{6}{4} = 1,5
\end{equation*}

\begin{equation*}
  var(X) = 1,5 - [1]^2 = 0,5
\end{equation*}

- Para três jogadas:CCC; CCK; CKC; KCC; CKK; KCK; KKC; KKK. Ou seja,
\begin{equation*}
  E(X) = 3 \times \frac{1}{8} + 2 \times \frac{3}{8} + 1 \times \frac{3}{8} + 0 \times \frac{1}{8} = \frac{12}{8} = 1,5
\end{equation*}

\begin{equation*}
  E(X^2) = 3^2\times \frac{1}{8} + 2^2 \times \frac{3}{8} + 1^2 \times \frac{3}{8} +  0^2\times \frac{1}{8} = \frac{24}{8} = 3
\end{equation*}

\begin{equation*}
  var(X) = 3 - [1,5]^2 = 0,75
\end{equation*}

### Média e Variância da distribuição binomial

Com base nos resultados do exemplo numérico anterior tem-se:

A média da distribuição binomial

\begin{equation*}
  E(X) = np
\end{equation*}

A variância da distribuição binomial

\begin{equation*}
  var(X) = np(1-p)
\end{equation*}

### Distribuição Binomial usando o R
Considerando que:

 **x** é um vetor de números;

 **p** é um vetor de probabilidades; 

 **n** é o número de observações;

 **tamanho** é o número de experimentos ou tentativas e;

 **prob** é a probabilidade de sucesso de cada experimento ou tentativa. 

Seguem-se quatro funções no R para a distribuição binomial.

**dbinom(x, tamanho, prob)**: 

esta função entrega a distribuição densidade de probabilidade a cada ponto.

**pbinom(x, tamanho, prob)**: 

esta função entrega a probabilidade cumulativa de um evento. Ou seja, é um único valor representando probabilidade.

**qbinom(p, tamanho, prob)**: 

esta função toma o valor da probabilidade e entrega um número cujo valor cumulativo coincide com o valor da probabilidade.

**rbinom(n, tamanho, prob)**: 

esta função gera o número requerido de valores aleatórios de uma dada probabilidade.

**Exemplo numérico de distribuição binomial resolvido usando o R**

O primeiro exemplo numérico 3.2.3.1 da página 62 de @Sartoris2013 resolvido anteriormente é agora resolvido usando-se o R. Suponha um jogo de dados em que aposta em um único número. Determine as seguintes probabilidades:

 - em três jogadas, ganhar duas.

```{r ex3231a, echo=TRUE}
library(MASS)

p1 <- dbinom(2,3,1/6)
p1

p1frac <- fractions(p1)
p1frac
```

 - em quatro jogadas, ganhar duas.
 
```{r ex3231b, echo=TRUE}
library(MASS)
p2 <- dbinom(2,4,1/6)
p2

p2frac <- fractions(p2)
p2frac
```

- Em cinco jogadas, ganhar três.

```{r ex3231c, echo=TRUE}
library(MASS)

p3 <- dbinom(3,5,1/6)
p3

p3frac <- fractions(p3)
p3frac
```

**O segundo exemplo numérico de distribuição binomial usando R**

O segundo exemplo numérico resolvido é o exemplo 3.2.3.2 da página 63 de @Sartoris2013 é agora resolvido usando-se o R. Calcule a média e a variância 
no jogo  de cara ou coroa, atribuindo valor um para cara e zero para coroa. 
Considerando uma ,duas e três jogadas.

- Para uma jogada, que é o caso particular da distribuição de Bernoulli.

```{r ex3232a, echo=TRUE}
media1 <- 1*0.5
media1
var1 <- 1*0.5*(1 - 0.5)
var1
```

- Para duas jogadas: CC; CK; KC; KK.

```{r ex3232b, echo=TRUE}
media2 <- 2*0.5
media2
var2 <- 2*0.5*(1 - 0.5)
var2
```
- Para três jogadas: CCC; CCK; CKC; KCC; CKK; KCK; KKC; KKK.

```{r ex3232c, echo=TRUE}
media3 <- 3*0.5
media3

var3 <- 3*0.5*(1 - 0.5)
var3
```

## Distribuição de Poisson

- Morte por patada de cavalo, mesmo para a época em que o principal meio de 
transporte era a cavalo, era um acontecimento pouco usual.
- Celular do professor tocar durante a aula de Estatística Econômica poderia ser um exemplo de evento muito difícil de ocorrer.
- Para estas situações a probabilidade associada ao sucesso $p$ é muito pequena, mesmo considerando muitos meses ou muitas aulas. Ou seja, $n$ ser muito grande.
- Por isso, pode se pensar que $p$ tende a zero enquanto que $n$ tende ao $\infty$.

### Média e a Variância da Distribuição de Poisson

Partindo da distribuição binomial e como $p\rightarrow 0$ e $n\rightarrow\infty$ então
\begin{equation*}
  E(X) = np = \lambda.
\end{equation*}
Ou seja, $np$ é igual a um número finito $\lambda$ que significa o número médio de vezes que o evento ocorre.

Para a variância tem-se que

\begin{equation*}
  var(X) = \underbrace{np}_{\lambda}\underbrace{(1 - p)}_{1} = \lambda.
\end{equation*}
Ou seja, a média e a variância da distribuição de Poisson são iguais a $\lambda$.

### A função de probabilidade da distribuição de Poisson

A função de probabilidade para a distribuição de Poisson pode ser obtida a partir da função de probabilidade da distribuição binomial fazendo $p\rightarrow 0$ e $n\rightarrow \infty$.

\begin{equation*}
  P(X=k) = \frac{e^{-\lambda}\lambda^{k}}{k!}
\end{equation*}

A derivação matemática está no apêndice do capítulo 3 do Sartoris (2013).

**Primeiro exemplo numérico de distribuição de Poisson**

Exemplo 3.2.6.1 da página 67 de @Sartoris2013. Suponha que, em média, o telefone toque quatro vezes ao dia em uma casa. Qual a probabilidade de que, em certo dia, ele toque, no máximo, duas vezes?

\textbf{Resposta:} Trata-se de um problema sobre distribuição de Poisson cujo parâmetro é $\lambda= 4$. Note que pede-se a probabilidade de tocar 
\textbf{no máximo} duas vezes: $P(0) + P(1) + P(2)$.

\begin{align*}
  P(X=0) &=\frac{e^{-4}4^{0}}{0!} = 1e^{-4}\\
  P(X=1) &=\frac{e^{-4}4^{1}}{1!} = 4e^{-4}\\
  P(X=2) &=\frac{e^{-4}4^{2}}{2!} = 8e^{-4}
\end{align*}
Portanto:

\begin{equation*}
  P(X\leq 2) = 13e^{-4}\cong 0,2381 = 23,81\%
\end{equation*}

**Segundo exemplo numérico de distribuição de Poisson**

Exemplo 3.2.6.2 da página 67 de @Sartoris2013. Um candidato tem apenas 2\% das intenções de voto. Qual a probabilidade de que, em 100 eleitores escolhidos ao acaso, encontrem-se cinco que desejem votar nesse candidato?

\textbf{Resposta:} Usando a binomial pura e simplesmente

\begin{equation*}
  P(X=5) = \frac{100!}{5!(100-5)!}\times 0,02^5 \times 0,98^{95} \cong 0,0353 = 3,53\%
\end{equation*}

Note que o exercício pode ser resolvido usando a distribuição de Poisson como aproximação, tendo como parâmetro $\lambda = np = 100\times0,02 = 2$.

\begin{equation*}
  P(X=5) = \frac{e^{-2}2^{5}}{5!} \cong 0,0361 = 3,61\%
\end{equation*}

### Distribuição de Poisson usando o R

Considerando que:

 **x** é um vetor de números;

 **q** é um vetor de quantiles; 

 **p** é um vetor de probabilidades; 

 **n** é o número de observações;

 **lambda** é o vetor de médias não negativas;

Seguem-se quatro funções no R para a distribuição de Poisson.

**dpois(x, lambda)** : 

esta função entrega a distribuição densidade de probabilidade a cada ponto.

**ppois(q, lambda)**: 

esta função entrega a probabilidade cumulativa de um evento. Ou seja, é um único valor representando probabilidade.

**qpois(p, lambda)**: 

esta função toma o valor da probabilidade e entrega um número cujo valor cumulativo coincide com o valor da probabilidade.

**rpois(n, lambda)**: 

esta função gera o número de requerido de valores aleatórios de uma dada probabilidade a partir de uma dada amostra.

**O primeiro exemplo numérico de distribuição de Poisson resolvido usando R**

Exemplo 3.2.6.1 da página 67 de @Sartoris2013. Suponha que, em média, o telefone toque quatro vezes ao dia em uma casa. Qual a probabilidade de que, em certo dia, ele toque, no máximo, duas vezes?

```{r ex3261a, echo=TRUE}
p4 <- round(ppois(2,4),4)
p4
```

**O segundo exemplo numérico de distribuição de Poisson resolvido usando R**

Exemplo 3.2.6.2 da página 67 de @Sartoris2013. Um candidato tem apenas 2\% das intenções de voto. Qual a probabilidade de que, em 100 eleitores escolhidos ao acaso, encontrem-se cinco que desejem votar nesse candidato?

Usando distribuição binomial:

```{r ex3262a, echo=TRUE}
p5 <- round(dbinom(5,100,0.02),4)
p5
```

Usando a distribuição de Poisson como aproximação e sabendo que $\lambda = np = 100\times 0,02 = 2$

```{r ex3262b, echo=TRUE}
p6 <- round(dpois(5,2),4)
p6
```

