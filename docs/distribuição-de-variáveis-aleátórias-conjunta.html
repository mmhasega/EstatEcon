<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>CAPÍTULO 6 Distribuição de variáveis aleátórias conjunta | Notas de aulas de Estatística Econômica</title>
  <meta name="description" content="Trata-se do material usado nas aulas de Estatística Econômica e Introdução à Econometria SE305 do curso de Economia da Universidade Federal do Paranà." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="CAPÍTULO 6 Distribuição de variáveis aleátórias conjunta | Notas de aulas de Estatística Econômica" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Trata-se do material usado nas aulas de Estatística Econômica e Introdução à Econometria SE305 do curso de Economia da Universidade Federal do Paranà." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="CAPÍTULO 6 Distribuição de variáveis aleátórias conjunta | Notas de aulas de Estatística Econômica" />
  
  <meta name="twitter:description" content="Trata-se do material usado nas aulas de Estatística Econômica e Introdução à Econometria SE305 do curso de Economia da Universidade Federal do Paranà." />
  

<meta name="author" content="Marcos Minoru Hasegawa" />


<meta name="date" content="2020-11-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="variável-aleatória-contínua.html"/>
<link rel="next" href="estimadores.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notas de aulas de Estatística Econômica</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Licença</a></li>
<li class="chapter" data-level="" data-path="sobre-o-material.html"><a href="sobre-o-material.html"><i class="fa fa-check"></i>Sobre o material</a></li>
<li class="chapter" data-level="" data-path="sobre-o-autor.html"><a href="sobre-o-autor.html"><i class="fa fa-check"></i>Sobre o Autor</a></li>
<li class="chapter" data-level="1" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html"><i class="fa fa-check"></i><b>1</b> Estatística Descritiva</a><ul>
<li class="chapter" data-level="1.1" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#medidas-de-posição"><i class="fa fa-check"></i><b>1.1</b> Medidas de posição</a><ul>
<li class="chapter" data-level="1.1.1" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#variável-aleatória"><i class="fa fa-check"></i><b>1.1.1</b> Variável Aleatória</a></li>
<li class="chapter" data-level="1.1.2" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#média-aritmética-simples"><i class="fa fa-check"></i><b>1.1.2</b> Média Aritmética Simples</a></li>
<li class="chapter" data-level="1.1.3" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#média-aritmética-ponderada"><i class="fa fa-check"></i><b>1.1.3</b> Média Aritmética Ponderada</a></li>
<li class="chapter" data-level="1.1.4" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#média-geométrica-simples"><i class="fa fa-check"></i><b>1.1.4</b> Média Geométrica Simples</a></li>
<li class="chapter" data-level="1.1.5" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#média-geométrica-ponderada"><i class="fa fa-check"></i><b>1.1.5</b> Média Geométrica Ponderada</a></li>
<li class="chapter" data-level="1.1.6" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#média-harmônica"><i class="fa fa-check"></i><b>1.1.6</b> Média Harmônica</a></li>
<li class="chapter" data-level="1.1.7" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#média-harmônica-ponderada"><i class="fa fa-check"></i><b>1.1.7</b> Média Harmônica Ponderada</a></li>
<li class="chapter" data-level="1.1.8" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#mediana"><i class="fa fa-check"></i><b>1.1.8</b> Mediana</a></li>
<li class="chapter" data-level="1.1.9" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#quartis-ou-quartiles"><i class="fa fa-check"></i><b>1.1.9</b> Quartis ou Quartiles</a></li>
<li class="chapter" data-level="1.1.10" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#moda"><i class="fa fa-check"></i><b>1.1.10</b> Moda</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#medidas-de-dispersão"><i class="fa fa-check"></i><b>1.2</b> Medidas de dispersão</a><ul>
<li class="chapter" data-level="1.2.1" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#amplitude"><i class="fa fa-check"></i><b>1.2.1</b> Amplitude</a></li>
<li class="chapter" data-level="1.2.2" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#variância"><i class="fa fa-check"></i><b>1.2.2</b> Variância</a></li>
<li class="chapter" data-level="1.2.3" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#desvio-padrão"><i class="fa fa-check"></i><b>1.2.3</b> Desvio Padrão</a></li>
<li class="chapter" data-level="1.2.4" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#desvio-absoluto-médio"><i class="fa fa-check"></i><b>1.2.4</b> Desvio Absoluto Médio</a></li>
<li class="chapter" data-level="1.2.5" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#diferença-absoluta-média"><i class="fa fa-check"></i><b>1.2.5</b> Diferença Absoluta Média</a></li>
<li class="chapter" data-level="1.2.6" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#histograma"><i class="fa fa-check"></i><b>1.2.6</b> Histograma</a></li>
<li class="chapter" data-level="1.2.7" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#diagrama-de-caixa-boxplot"><i class="fa fa-check"></i><b>1.2.7</b> Diagrama de caixa (Boxplot)</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#medidas-de-relação-linear-entre-duas-variáveis"><i class="fa fa-check"></i><b>1.3</b> Medidas de relação linear entre duas variáveis</a><ul>
<li class="chapter" data-level="1.3.1" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#covariância"><i class="fa fa-check"></i><b>1.3.1</b> Covariância</a></li>
<li class="chapter" data-level="1.3.2" data-path="estatística-descritiva.html"><a href="estatística-descritiva.html#coeficiente-de-correlação"><i class="fa fa-check"></i><b>1.3.2</b> Coeficiente de Correlação</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html"><i class="fa fa-check"></i><b>2</b> Medidas de desigualdade</a><ul>
<li class="chapter" data-level="2.1" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#príncipio-de-pigou-dalton"><i class="fa fa-check"></i><b>2.1</b> Príncipio de Pigou-Dalton</a></li>
<li class="chapter" data-level="2.2" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#transferência-regressiva"><i class="fa fa-check"></i><b>2.2</b> Transferência Regressiva</a></li>
<li class="chapter" data-level="2.3" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#curva-de-lorenz"><i class="fa fa-check"></i><b>2.3</b> Curva de Lorenz</a></li>
<li class="chapter" data-level="2.4" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#índice-gini"><i class="fa fa-check"></i><b>2.4</b> Índice Gini</a></li>
<li class="chapter" data-level="2.5" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#discrepância-máxima"><i class="fa fa-check"></i><b>2.5</b> Discrepância Máxima</a></li>
<li class="chapter" data-level="2.6" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#redundância-e-índice-de-theil"><i class="fa fa-check"></i><b>2.6</b> Redundância e Índice de Theil</a><ul>
<li class="chapter" data-level="2.6.1" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#teoria-da-informação"><i class="fa fa-check"></i><b>2.6.1</b> Teoria da Informação</a></li>
<li class="chapter" data-level="2.6.2" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#índice-t-de-theil"><i class="fa fa-check"></i><b>2.6.2</b> Índice T de Theil</a></li>
<li class="chapter" data-level="2.6.3" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#índice-de-l-de-theil"><i class="fa fa-check"></i><b>2.6.3</b> Índice de L de Theil</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="medidas-de-desigualdade.html"><a href="medidas-de-desigualdade.html#variância-dos-logaritmos"><i class="fa fa-check"></i><b>2.7</b> Variância dos Logaritmos</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="números-índices.html"><a href="números-índices.html"><i class="fa fa-check"></i><b>3</b> Números-Índices</a><ul>
<li class="chapter" data-level="3.1" data-path="números-índices.html"><a href="números-índices.html#introdução"><i class="fa fa-check"></i><b>3.1</b> Introdução</a></li>
<li class="chapter" data-level="3.2" data-path="números-índices.html"><a href="números-índices.html#preços-relativos"><i class="fa fa-check"></i><b>3.2</b> Preços Relativos</a></li>
<li class="chapter" data-level="3.3" data-path="números-índices.html"><a href="números-índices.html#índice-simples-de-preços-agregados"><i class="fa fa-check"></i><b>3.3</b> Índice Simples de Preços Agregados</a></li>
<li class="chapter" data-level="3.4" data-path="números-índices.html"><a href="números-índices.html#média-aritmética-dos-preços-relativos"><i class="fa fa-check"></i><b>3.4</b> Média Aritmética dos Preços Relativos</a></li>
<li class="chapter" data-level="3.5" data-path="números-índices.html"><a href="números-índices.html#índice-de-preços-de-laspeyres"><i class="fa fa-check"></i><b>3.5</b> Índice de Preços de Laspeyres</a></li>
<li class="chapter" data-level="3.6" data-path="números-índices.html"><a href="números-índices.html#índice-de-preços-de-paasche"><i class="fa fa-check"></i><b>3.6</b> Índice de Preços de Paasche</a></li>
<li class="chapter" data-level="3.7" data-path="números-índices.html"><a href="números-índices.html#índice-de-preços-de-fisher"><i class="fa fa-check"></i><b>3.7</b> Índice de Preços de Fisher</a></li>
<li class="chapter" data-level="3.8" data-path="números-índices.html"><a href="números-índices.html#índice-de-preços-de-marshall-edgeworth"><i class="fa fa-check"></i><b>3.8</b> Índice de Preços de Marshall-Edgeworth</a></li>
<li class="chapter" data-level="3.9" data-path="números-índices.html"><a href="números-índices.html#deflacionamento"><i class="fa fa-check"></i><b>3.9</b> Deflacionamento</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html"><i class="fa fa-check"></i><b>4</b> Variável Aleatória Discreta</a><ul>
<li class="chapter" data-level="4.1" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#esperança-matemática"><i class="fa fa-check"></i><b>4.1</b> Esperança matemática</a><ul>
<li class="chapter" data-level="4.1.1" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#função-de-probabilidade"><i class="fa fa-check"></i><b>4.1.1</b> Função de Probabilidade</a></li>
<li class="chapter" data-level="4.1.2" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#função-distribuição-acumulada"><i class="fa fa-check"></i><b>4.1.2</b> Função distribuição acumulada</a></li>
<li class="chapter" data-level="4.1.3" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#esperanças-variâncias-e-covariâncias"><i class="fa fa-check"></i><b>4.1.3</b> Esperanças, Variâncias e Covariâncias</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#variável-aleatória-discreta-1"><i class="fa fa-check"></i><b>4.2</b> Variável Aleatória Discreta</a></li>
<li class="chapter" data-level="4.3" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#distribuição-uniforme"><i class="fa fa-check"></i><b>4.3</b> Distribuição Uniforme</a></li>
<li class="chapter" data-level="4.4" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#distribuição-de-bernoulli"><i class="fa fa-check"></i><b>4.4</b> Distribuição de Bernoulli</a></li>
<li class="chapter" data-level="4.5" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#distribuição-binomial"><i class="fa fa-check"></i><b>4.5</b> Distribuição Binomial</a><ul>
<li class="chapter" data-level="4.5.1" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#média-e-variância-da-distribuição-binomial"><i class="fa fa-check"></i><b>4.5.1</b> Média e Variância da distribuição binomial</a></li>
<li class="chapter" data-level="4.5.2" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#distribuição-binomial-usando-o-r"><i class="fa fa-check"></i><b>4.5.2</b> Distribuição Binomial usando o R</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#distribuição-de-poisson"><i class="fa fa-check"></i><b>4.6</b> Distribuição de Poisson</a><ul>
<li class="chapter" data-level="4.6.1" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#média-e-a-variância-da-distribuição-de-poisson"><i class="fa fa-check"></i><b>4.6.1</b> Média e a Variância da Distribuição de Poisson</a></li>
<li class="chapter" data-level="4.6.2" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#a-função-de-probabilidade-da-distribuição-de-poisson"><i class="fa fa-check"></i><b>4.6.2</b> A função de probabilidade da distribuição de Poisson</a></li>
<li class="chapter" data-level="4.6.3" data-path="variável-aleatória-discreta.html"><a href="variável-aleatória-discreta.html#distribuição-de-poisson-usando-o-r"><i class="fa fa-check"></i><b>4.6.3</b> Distribuição de Poisson usando o R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="variável-aleatória-contínua.html"><a href="variável-aleatória-contínua.html"><i class="fa fa-check"></i><b>5</b> Variável Aleatória Contínua</a><ul>
<li class="chapter" data-level="5.1" data-path="variável-aleatória-contínua.html"><a href="variável-aleatória-contínua.html#distribuições-contínuas"><i class="fa fa-check"></i><b>5.1</b> Distribuições contínuas</a><ul>
<li class="chapter" data-level="5.1.1" data-path="variável-aleatória-contínua.html"><a href="variável-aleatória-contínua.html#função-de-distribuição-de-variáveis-contínuas"><i class="fa fa-check"></i><b>5.1.1</b> Função de distribuição de variáveis contínuas</a></li>
<li class="chapter" data-level="5.1.2" data-path="variável-aleatória-contínua.html"><a href="variável-aleatória-contínua.html#esperança-e-variância-de-variáveis-aleatórias-contínuas"><i class="fa fa-check"></i><b>5.1.2</b> Esperança e variância de variáveis aleatórias contínuas</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="variável-aleatória-contínua.html"><a href="variável-aleatória-contínua.html#distribuição-normal"><i class="fa fa-check"></i><b>5.2</b> Distribuição Normal</a></li>
<li class="chapter" data-level="5.3" data-path="variável-aleatória-contínua.html"><a href="variável-aleatória-contínua.html#teorema-de-tchebichev"><i class="fa fa-check"></i><b>5.3</b> Teorema de Tchebichev</a></li>
<li class="chapter" data-level="5.4" data-path="variável-aleatória-contínua.html"><a href="variável-aleatória-contínua.html#momentos-de-uma-distribuição"><i class="fa fa-check"></i><b>5.4</b> Momentos de uma distribuição</a><ul>
<li class="chapter" data-level="5.4.1" data-path="variável-aleatória-contínua.html"><a href="variável-aleatória-contínua.html#posição-da-média-da-mediana-e-da-moda-numa-distribuição-assimétrica"><i class="fa fa-check"></i><b>5.4.1</b> Posição da média, da mediana e da moda numa distribuição assimétrica</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html"><i class="fa fa-check"></i><b>6</b> Distribuição de variáveis aleátórias conjunta</a><ul>
<li class="chapter" data-level="6.1" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#distribuição-de-probabilidade-conjunta-de-variáveis-aleatórias-discretas"><i class="fa fa-check"></i><b>6.1</b> Distribuição de probabilidade conjunta de variáveis aleatórias discretas</a><ul>
<li class="chapter" data-level="6.1.1" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#covariância-e-correlação-no-contexto-da-distribuição-de-probabilidade-conjunta"><i class="fa fa-check"></i><b>6.1.1</b> Covariância e correlação no contexto da distribuição de probabilidade conjunta</a></li>
<li class="chapter" data-level="6.1.2" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#esperança-condicionada"><i class="fa fa-check"></i><b>6.1.2</b> Esperança condicionada</a></li>
<li class="chapter" data-level="6.1.3" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#lei-das-expectativas-iteradas"><i class="fa fa-check"></i><b>6.1.3</b> Lei das Expectativas Iteradas</a></li>
<li class="chapter" data-level="6.1.4" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#variância-condicionada"><i class="fa fa-check"></i><b>6.1.4</b> Variância condicionada</a></li>
<li class="chapter" data-level="6.1.5" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#decomposição-da-variância"><i class="fa fa-check"></i><b>6.1.5</b> Decomposição da Variância</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#distribuição-de-probabilidade-conjunta-de-variáveis-aleatórias-contínuas"><i class="fa fa-check"></i><b>6.2</b> Distribuição de probabilidade conjunta de variáveis aleatórias contínuas</a><ul>
<li class="chapter" data-level="6.2.1" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#função-densidade-de-probabilidade-conjunta"><i class="fa fa-check"></i><b>6.2.1</b> Função densidade de probabilidade conjunta</a></li>
<li class="chapter" data-level="6.2.2" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#função-densidade-de-probabilidade-marginal"><i class="fa fa-check"></i><b>6.2.2</b> Função densidade de probabilidade marginal</a></li>
<li class="chapter" data-level="6.2.3" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#probabilidade-condicional"><i class="fa fa-check"></i><b>6.2.3</b> Probabilidade condicional</a></li>
<li class="chapter" data-level="6.2.4" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#esperança-matemática-de-x"><i class="fa fa-check"></i><b>6.2.4</b> Esperança matemática de <span class="math inline">\(x\)</span></a></li>
<li class="chapter" data-level="6.2.5" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#variância-de-x"><i class="fa fa-check"></i><b>6.2.5</b> Variância de <span class="math inline">\(x\)</span></a></li>
<li class="chapter" data-level="6.2.6" data-path="distribuição-de-variáveis-aleátórias-conjunta.html"><a href="distribuição-de-variáveis-aleátórias-conjunta.html#covariância-entre-x-e-y"><i class="fa fa-check"></i><b>6.2.6</b> Covariância entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimadores.html"><a href="estimadores.html"><i class="fa fa-check"></i><b>7</b> Estimadores</a></li>
<li class="chapter" data-level="8" data-path="teste-de-hipóste.html"><a href="teste-de-hipóste.html"><i class="fa fa-check"></i><b>8</b> Teste de hipóste</a></li>
<li class="chapter" data-level="9" data-path="regressão-linear.html"><a href="regressão-linear.html"><i class="fa fa-check"></i><b>9</b> Regressão Linear</a></li>
<li class="chapter" data-level="" data-path="referências.html"><a href="referências.html"><i class="fa fa-check"></i>Referências</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado com bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas de aulas de Estatística Econômica</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="distribuição-de-variáveis-aleátórias-conjunta" class="section level1">
<h1><span class="header-section-number">CAPÍTULO 6</span> Distribuição de variáveis aleátórias conjunta</h1>
<p><strong>Probabilidade conjunta</strong> é a probabilidade que se refere a duas ou mais variáveis aleatórias simultaneamente.</p>
<p>A distribuição de probabilidade de um vetor <span class="math inline">\((X,Y)\)</span> com duas variáveis, por exemplo,m seria o caso bidimensional. Como o material sobre este assunto é baseado em <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>, a apresentação da distribuição de variáveis aleatórias conjuntas será o caso bidimensional.</p>
<p>As variáveis da distribuição de probabilidade conjunta podem ser discretas ou contínuas.</p>
<div id="distribuição-de-probabilidade-conjunta-de-variáveis-aleatórias-discretas" class="section level2">
<h2><span class="header-section-number">6.1</span> Distribuição de probabilidade conjunta de variáveis aleatórias discretas</h2>
<p>Com base em <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>, é apresentado o assunto da seção através da apresentação de um exemplo numérico prático.</p>
<p>Seja um time de volei que vai dispoutar um campeonato muito equilibrado, em que a probabilidade de ganhar ou perder uma partida é de 0,5. O técnico pede ao estatístico da equipe que faça uma análise das probabilidades das três primeiras partidas consideradas vitais para o restante do campeonato. Em particular, a vitória na primeira partida é considerada decisiva pela comissão técnica.</p>
<p>O estátistico define duas variáveis, <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, sendo que</p>
<ul>
<li><p><span class="math inline">\(X\)</span> é o número de vitórias obtidas nos três primeiros jogos e;</p></li>
<li><p><span class="math inline">\(Y\)</span> é igual a 1, caso ocorra vitória no primeiro jogo e zero, caso ocorra o contrário.</p></li>
</ul>
<p>Por enquanto considera-se que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> são variáveis independentes.</p>
<p>Como são três jogos com dois resultados possíveis, vitória ou derrota com 0,5 de probabilidade cada um, existem oito possibilidades entre os três primeiros jogos em análise. Na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ResultadosProvaveisEmTresPartidas">6.1</a> abaixo é apresentado os valores de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> de acordo com os resultados possíveis.</p>
<table style="width:99%;">
<caption><span id="tab:ResultadosProvaveisEmTresPartidas">TABELA 6.1: </span> Resultados prováveis em três partidas, considerando vitória (V) ou derrota(D) como resultado possível de cada partida com 0,5 de probabilidade</caption>
<colgroup>
<col width="30%" />
<col width="32%" />
<col width="35%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">resultados
possíveis</th>
<th align="center">X</th>
<th align="center">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">VVV</td>
<td align="center">3</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">VVD</td>
<td align="center">2</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">VDV</td>
<td align="center">2</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">VDD</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">DVV</td>
<td align="center">2</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">DDV</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">DVD</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">DDD</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<p>Fonte: <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>.</p>
<p>Onde o resultado possível nos três primeiros jogos definido como VDV significa que o time teve vitória na primeira e na terceira partidas e derrota na segunda partida. Esse mesmo resultado VDV define que <span class="math inline">\(X=2\)</span> e <span class="math inline">\(Y=1\)</span> lembrando que <span class="math inline">\(X\)</span> é o número de vitórias entre as três partidas e <span class="math inline">\(Y\)</span> é igual a 1 se o time conseguiu vitória na primeira partida e zero se não conseguiu ganhar a primeira partida.</p>
<p>Na sequência o estatístico constrói uma tabela que apresenta as probabilidades conjuntas de <span class="math inline">\(x\)</span> e <span class="math inline">\(Y\)</span> cujo preenchimento é feito com base na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesConjuntasDeXeY">6.2</a></p>
<table style="width:75%;">
<caption><span id="tab:ProbabilidadesConjuntasDeXeY">TABELA 6.2: </span> Probabilidades conjuntas de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span></caption>
<colgroup>
<col width="13%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th align="center">X=0</th>
<th align="center">X=1</th>
<th align="center">X=2</th>
<th align="center">X=3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Y=0</strong></td>
<td align="center">1/8</td>
<td align="center">2/8</td>
<td align="center">1/8</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td><strong>Y=1</strong></td>
<td align="center">0</td>
<td align="center">1/8</td>
<td align="center">2/8</td>
<td align="center">1/8</td>
</tr>
</tbody>
</table>
<p>Com base na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesConjuntasDeXeY">6.2</a> é possível obter a probabilidade para um resultado com duas vitórias sendo que uma das duas vitórias foi na primeira partida:</p>
<p><span class="math display">\[
  P(X=2~\text{ e }~Y=1) = 2/8
\]</span>
Ou seja em oito resultados possíveis há duas combinações possíveis com resultado.</p>
<p>Veja que se o time ganha as três partidas <span class="math inline">\(X=3\)</span>, não é possível que <span class="math inline">\(Y=0\)</span> e por isso</p>
<p><span class="math display">\[
  P(X=3~\text{ e }~Y=0 ) = 0
\]</span></p>
<p>O inverso também é válido. Ou seja, se o time não ganhou nenhuma das três partidas, não é possivel que <span class="math inline">\(Y=1\)</span> e por isso</p>
<p><span class="math display">\[
  P(X=0~\text{ e }~Y=1) = 0
\]</span></p>
<p>Ainda com base na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesConjuntasDeXeY">6.2</a> é possível obter probabilidades só para valores de <span class="math inline">\(X\)</span> e probabilidades só para valores de <span class="math inline">\(Y\)</span>. Ou seja, para obter a probabilidade de <span class="math inline">\(X=1\)</span> é ncessário somar todas as probabilidades conjuntas que tem <span class="math inline">\(X=1\)</span>
<span class="math display">\[
  P(X = 1) = P(X=1~\text{ e }~Y=0) + P(X=1~\text{ e }~Y=1) = 2/8 + 1/8 = 3/8.
\]</span>
Na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesConjuntasDeXeY">6.2</a>, <span class="math inline">\(P(X = 1)\)</span> é obtida somando os valores da coluna para <span class="math inline">\(X=1\)</span>.
Também é possível obter o valor da probabilidade de <span class="math inline">\(Y=1\)</span> que é simplesmente a soma de todos as probabilidades conjuntas que tem <span class="math inline">\(Y=1\)</span>
<span class="math display">\[
  P(Y=1) = P(X=0~\text{ e }~Y=1) + P(X=1~\text{ e }~Y=1) +P(X=2~\text{ e }~Y=1) + P(X=3~\text{ e }~Y=1)
\]</span>
ou seja,
<span class="math display">\[
  P(Y=1) = 0 + 1/8 +2/8 + 1/8 = 1/2
\]</span>
Na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesConjuntasDeXeY">6.2</a>, <span class="math inline">\(P(Y=1)\)</span> é obtida somando os valores da linha para <span class="math inline">\(Y=1\)</span>.
Assim, usando este raciocínio, é possível agregar mais uma linha e mais uma coluna com as probabilidades marginais de <span class="math inline">\(X\)</span> e de <span class="math inline">\(Y\)</span>. As probabilidades marginais de <span class="math inline">\(X\)</span> são as somas de cada uma das colunas da tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesConjuntasDeXeY">6.2</a>. As probabilidades marginais de <span class="math inline">\(Y\)</span> são as somas de cada uma das linhas da tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesConjuntasDeXeY">6.2</a>. Desta forma se obtém a tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesMarginaisDeXeY">6.3</a>.</p>
<table style="width:90%;">
<caption><span id="tab:ProbabilidadesMarginaisDeXeY">TABELA 6.3: </span> Probabilidades marginais de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span></caption>
<colgroup>
<col width="13%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th align="center">X=0</th>
<th align="center">X=1</th>
<th align="center">X=2</th>
<th align="center">X=3</th>
<th align="center">P(Y)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Y=0</strong></td>
<td align="center">1/8</td>
<td align="center">2/8</td>
<td align="center">1/8</td>
<td align="center">0</td>
<td align="center"><strong>1/2</strong></td>
</tr>
<tr class="even">
<td><strong>Y=1</strong></td>
<td align="center">0</td>
<td align="center">1/8</td>
<td align="center">2/8</td>
<td align="center">1/8</td>
<td align="center"><strong>1/2</strong></td>
</tr>
<tr class="odd">
<td><strong>P(X)</strong></td>
<td align="center"><strong>1/8</strong></td>
<td align="center"><strong>3/8</strong></td>
<td align="center"><strong>3/8</strong></td>
<td align="center"><strong>1/8</strong></td>
<td align="center"><strong>1</strong></td>
</tr>
</tbody>
</table>
<p>Com base na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesMarginaisDeXeY">6.3</a> é possível calcular a probabilidade condicional, embora não possa ser obtida diretamente da fonte.</p>
<p>Suponha a seguinte pergunta com base neste exemplo numérico prático: qual é probabilidade de time ganhar apenas uma partida entre as três dado que essa partida ocorre na primeira partida? Em notação matemática seria</p>
<p><span class="math display">\[
  P(X=1|Y=1) = \text{??}
\]</span></p>
<p>Lembrando das aulas de teoria da probabilidade, a probabilidade condicional e dada da seguinte forma:</p>
<p><span class="math display">\[
  P(X=x|Y=y) = \dfrac{P (X=x~\cap~Y=y)}{P(Y=y)}
\]</span></p>
<p>onde <span class="math inline">\(P (X=x~\cap~Y=y)\)</span> é a probabilidade conjunta entre <span class="math inline">\(X=x\)</span> e <span class="math inline">\(Y=y\)</span> e <span class="math inline">\(P(Y=y)\)</span> é a probabilidade marginal de <span class="math inline">\(Y=y\)</span>.</p>
<p>Assim, podemos calcular a probabilidade condicional <span class="math inline">\(P(X=1|Y=1)\)</span></p>
<p><span class="math display">\[
  P(X=1|Y=1) = \dfrac{P (X=1~\cap~Y=1)}{P(Y=1)} = \dfrac{1/8}{1/2} = 1/4
\]</span></p>
<p>Dado que <span class="math inline">\(Y=1\)</span>, só existe quatro possibilidades para essa situação, dos quais apenas uma situação tem <span class="math inline">\(X=1\)</span>.</p>
<p>Note que o contrário também é possível obter. Ou seja considere a probabilidade condicional da seguinte forma:</p>
<p><span class="math display">\[
  P(Y=y|X=x) = \dfrac{P (Y=y~\cap~X=x)}{P(X=x)}.
\]</span></p>
<p>Com base no exemplo do time de volei, qual é probabilidade condicional de que o time não vença na primeira partida dado que o time ganhe duas entre as três partidas?</p>
<p><span class="math display">\[
  P(Y=0|X=2) = \dfrac{P (Y=0~\cap~X=2)}{P(X=2)}.
\]</span>
Consultando a tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesMarginaisDeXeY">6.3</a> se tem</p>
<p><span class="math display">\[
  P(Y=0|X=2) = \dfrac{P (Y=0~\cap~X=2)}{P(X=2)} = \dfrac{1/8}{3/8} = 1/3
\]</span></p>
<p>Agora sabendo calcular a probabilidade condicional é possível verificar se as variáveis são independentes ou não. Para isso toma-se as situações de probabilidade conjunta igual a zero na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesMarginaisDeXeY">6.3</a>. Note que se o time ganha as três partidas, não há possbilidade da variável <span class="math inline">\(Y\)</span> assumir o valor 0. Veja o outro valor zero. Quando o time não ganha nenhuma das três primeiras partidas não é possível a variável <span class="math inline">\(Y\)</span> assumir valor igual a 1. A variável <span class="math inline">\(Y\)</span> sendo igual a 1 necessariamente o time tem que ter ganho a primeira partida.Por isso as variáveis <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> do exemplo do time de volei não são independentes.</p>
<p>Então uma forma de verificar se as variáveis são independentes ou não é verificar se a probabilidade condicional é igual a probabilidade marginal. Ou seja,</p>
<p><span class="math display">\[
P(X=x|Y=y) = P(X=x)
\]</span>
ou
<span class="math display">\[
P(Y=y|X=x) = P(Y=y)
\]</span>
Caso as probabilidades condicionais não sejam iguais a sua respectiva probabilidade marginal, então as duas variáveis <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> não são independentes. Com base na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesMarginaisDeXeY">6.3</a>, toma-se, por exemplo,
a probabilidade conjunta para <span class="math inline">\(X=1\)</span> e <span class="math inline">\(Y=1\)</span>
<span class="math display">\[
  P(X=1|Y=1) =1/4
\]</span>
e a probabilidade marginal <span class="math inline">\(X=1\)</span>
<span class="math display">\[
  p(X=1) = 3/8
\]</span>
são diferentes. Portanto <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> não são independentes. Basta somente um par de valores de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> apresentar essa diferença para poder concluir que as variáveis são dependentes uma da outra. Para verificar se as variáveis são independentes, é necessário verificar se todos o pares possíveis tem probabilidade condicional igual a probabilidade incondicional. Note que a probabilidade marginal é denominada também de probabilidade incondicional.</p>
<p>Ou seja, basta somente uma situação com</p>
<p><span class="math display">\[
  P(X=x | Y=y) \neq P(X=x)
\]</span></p>
<p>para que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> seja dependentes.</p>
<div id="covariância-e-correlação-no-contexto-da-distribuição-de-probabilidade-conjunta" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Covariância e correlação no contexto da distribuição de probabilidade conjunta</h3>
<p>O cálculo do valor esperado bem como da variância de variáveis distribuídas conjutamente não é problema pois é possível obter as probabilidades marginais facilmente a partir das probabilidades conjuntas. O que há de novo, mas nem tanto, é sobre o cálculo da covariância e da correlação, que é apresentado na forma de exemplo numérico a seguir.</p>
<p><strong>Exemplo numérico sobre covariância e correlação para a distribuição conjunta</strong></p>
<p>Exemplo 5.1.1 da página 112 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Calcule com base nos dados do exemplo numérico sobre o time de volei:</p>
<ul>
<li>o valor esperado de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>;</li>
<li>as variâncias de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>;</li>
<li>a covariância entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>;</li>
<li>a correlação entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</li>
</ul>
<p>Para calcular <span class="math inline">\(E(X)\)</span> utiliza-se as probabilidades marginais de <span class="math inline">\(X\)</span> que estão na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProbabilidadesMarginaisDeXeY">6.3</a></p>
<p><span class="math display">\[
E(X) = \sum_{i=1}^{n}P(X_i)X_i
\]</span></p>
<p><span class="math display">\[
E(X) =  P(X_1)\times X_1 + P(X_2)\times X_2 + P(X_3)\times X_3 + P(X_4)\times X_4
\]</span></p>
<p>Portanto,</p>
<p><span class="math display">\[
E(X) =  1/8\times 0 + 3/8\times 1  + 3/8\times 2 + 1/8\times 3 = 12/8 = 1,5
\]</span></p>
<p>A esperança matemática de <span class="math inline">\(x\)</span> do exemplo numérico é 1,5.</p>
<p>Para <span class="math inline">\(Y\)</span></p>
<p><span class="math display">\[
  E(Y) = \frac{1}{2}\times 0 + \frac{1}{2} \times 1 = 0,5
\]</span></p>
<p>Para calular a variância de <span class="math inline">\(X\)</span> usando a fórmula alternativa</p>
<p><span class="math display">\[
Var(X) = E(X^2) - [E(X)]^2
\]</span></p>
<p>Assim só está faltando calcular a esperança do quadrdado de <span class="math inline">\(X\)</span></p>
<p><span class="math display">\[
E(X^2) = \sum_{i=1}^{n} P(X_i) \times X_i^2 = P(X_1)\times X_1^{2} + \ldots + P(X_n)\times X_{n}^{2}
\]</span></p>
<p>Protanto,</p>
<p><span class="math display">\[
E(X^2) = \frac{1}{8}\times 0^{2} + \frac{3}{8} \times 1^2 + \frac{3}{8} \times 2^{2} + \frac{1}{8} \times 3^2 = \frac{24}{8} = 3
\]</span>
Com <span class="math inline">\(E(X)\)</span> e <span class="math inline">\(E(X^2)\)</span></p>
<p><span class="math display">\[
  Var(X) = E(X^2) - [E(X)]^2 = 3 - (1,5)^2 = 3 - 2,25 = 0,75.
\]</span></p>
<p>Para a variância de <span class="math inline">\(Y\)</span> é necessário calcular <span class="math inline">\(E(Y^2)\)</span></p>
<p><span class="math display">\[
  E(Y^2) = \frac{1}{2}\times 0^2 + \frac{1}{2} \times 1^2 = 0,5
\]</span></p>
<p>Assim,</p>
<p><span class="math display">\[
 Var(Y) = E(Y^2) - [E(Y )]^2 = 0,5 - (0,5)^2 = 0,5 - 0,25 = 0,25
\]</span></p>
<p>Para calcular a covariancia entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, com base na fórmula alternativa,
<span class="math display">\[
  Cov(XY) = E(XY) - E(X)E(Y)
\]</span></p>
<p>é necessário calcular o produto entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> que segue na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProdutoEntreXeY">6.4</a>.</p>
<table style="width:67%;">
<caption><span id="tab:ProdutoEntreXeY">TABELA 6.4: </span> Produto entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span></caption>
<colgroup>
<col width="22%" />
<col width="22%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">X</th>
<th align="center">Y</th>
<th align="center">XY</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">3</td>
<td align="center">1</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">1</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center">1</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<p>Com base nos resultados de <span class="math inline">\(XY\)</span> apresentados na tabela <a href="distribuição-de-variáveis-aleátórias-conjunta.html#tab:ProdutoEntreXeY">6.4</a>, é possível obter as seguintes probabilidades</p>
<p><span class="math display">\[
  P(XY=0) = \frac{4}{8}
\]</span></p>
<p><span class="math display">\[
  P(XY = 1) = \frac{1}{8}
\]</span></p>
<p><span class="math display">\[
  P(XY = 2) = \frac{2}{8}
\]</span></p>
<p><span class="math display">\[
  P(XY = 3) = \frac{1}{8}.
\]</span></p>
<p>Assim</p>
<p><span class="math display">\[
  E(XY) = \sum_{i=1}^{n} P(X_iY_i) \times XY
\]</span></p>
<p><span class="math display">\[
  E(XY) = \frac{4}{8} \times 0 + \frac{1}{8}\times 1 + \frac{2}{8} \times 2 + \frac{1}{8} \times 3 = \frac{8}{8} = 1
\]</span></p>
<p>como já se tem calculado <span class="math inline">\(E(X)\)</span> e <span class="math inline">\(E(Y)\)</span></p>
<p><span class="math display">\[
  Cov(XY) = E(XY) - E(X)E(Y) = 1 - (1,5)(0,5) = 1 - 0,75 = 0,25
\]</span></p>
<p>Para o cálculo da correlação se tem todas as partes da sua fórmula calculadas</p>
<p><span class="math display">\[
  corr(XY) = \rho_{XY} = \dfrac{Cov(X,Y)}{\sqrt{Var(X) \times Var(Y)}} 
\]</span></p>
<p>Portanto</p>
<p><span class="math display">\[
  \rho_XY = \dfrac{0,25}{\sqrt{0,75 \times 0,25}} \cong 0,5774
\]</span></p>
</div>
<div id="esperança-condicionada" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Esperança condicionada</h3>
<p>A esperança condicionada é similar a esperança marginal ou incondicional sendo que as probabilidades associadas a variável em questão é a probabilidade condicionada que precisa ser previamente calculada, dado que é necessário ter a probabiliade conjunta e a probabilidade marginal ou incondicional para o seu cálculo. Ou seja se é probabilidade de <span class="math inline">\(X\)</span> dado <span class="math inline">\(Y\)</span></p>
<p><span class="math display">\[
  P(X=x|Y=y) = \dfrac{P (X=x~\cap~Y=y)}{P(Y=y)}
\]</span></p>
<p>para poder calcular a esperança condicionada de <span class="math inline">\(X\)</span> dado <span class="math inline">\(Y\)</span></p>
<p><span class="math display">\[
  E(X_i|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i.
\]</span></p>
<p><strong>Exemplo numérico sobre Esperança condicional</strong></p>
<p>Exemplo 5.1.2 da página 113 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Seja as variáveis aleatórias <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> definidas no exemplo sobre o time de volei, determine <span class="math inline">\(E(X|Y=0)\)</span>.</p>
<p><strong>Resposta</strong>:</p>
<p>Para o cálculo da esperança condicionada são necessárias as probabilidades condicionais para todos os valores de <span class="math inline">\(X\)</span>. Pois</p>
<p><span class="math display">\[
  E(X|Y=0) = \sum_{i=1}^{n} P(X_i|Y=0) \times X_i
\]</span>
As probabilidades condicionais são
<span class="math display">\[
  P((X=0|Y=0) = \dfrac{P(X=0~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]</span></p>
<p><span class="math display">\[
  P((X=1|Y=0) = \dfrac{P(X=1~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{2}{8}}{\dfrac{1}{2}}= \dfrac{1}{2}
\]</span></p>
<p><span class="math display">\[
  P((X=2|Y=0) = \dfrac{P(X=2~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]</span></p>
<p><span class="math display">\[
  P((X=3|Y=0) = \dfrac{P(X=3~\text{e}~Y=0)}{P(Y=0)}= \dfrac{0}{\dfrac{1}{2}}= 0
\]</span></p>
<p>Com essas probabilidades condicionais calcula-se a esperança de <span class="math inline">\(X\)</span> condicionada a <span class="math inline">\(Y=0\)</span></p>
<p><span class="math display">\[
  E(X|Y=0) = \frac{1}{4}\times 0 + \frac{1}{2} \times 1 + \frac{1}{4}\times 2 + 0 \times 3 = 1
\]</span>
Portanto a <span class="math inline">\(E(X|Y=0) = 1\)</span>.</p>
</div>
<div id="lei-das-expectativas-iteradas" class="section level3">
<h3><span class="header-section-number">6.1.3</span> Lei das Expectativas Iteradas</h3>
<p>A lei das expectativas iteradas diz que o valor esperados das esperanças condicionais é igual a esperança incondicional. Ou seja,</p>
<p><span class="math display" id="eq:ExpectativasIteradas">\[
  E[E(X|Y)] = E(X)
  \tag{6.1}
\]</span></p>
<p><strong>Exemplo sobre a Lei das Expectativas Iteradas</strong></p>
<p>O Exemplo 5.1.3 da página 114 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span> tem o objetivo de aplicar a lei das expectativas iteradas através de <a href="distribuição-de-variáveis-aleátórias-conjunta.html#eq:ExpectativasIteradas">(6.1)</a>. Seja as variáveis <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> do exemplo sobre o time de volei, determine <span class="math inline">\(E[E(X|Y)]\)</span>.</p>
<p><strong>Resposta</strong>:</p>
<p>Note que o cálculo da esperança das esperanças condicionais é necessário os todos as esperanças condicionais de <span class="math inline">\(X\)</span> e as respectivas probabilidades de <span class="math inline">\(Y\)</span>. Como já foi calculado <span class="math inline">\(E(X|Y=0)\)</span> no exemplo numérico anterior, fica faltando <span class="math inline">\(E(X|Y=1)\)</span>, uma vez que os valores de <span class="math inline">\(Y\)</span> são zero e um. Ou seja,</p>
<p>Para o cálculo da esperança condicionada de #<span class="math inline">\(X\)</span> dado que <span class="math inline">\(Y=1\)</span> são necessárias as probabilidades condicionais para todos os valores de <span class="math inline">\(X\)</span>. Pois</p>
<p><span class="math display">\[
  E(X|Y=1) = \sum_{i=1}^{n} P(X_i|Y=1) \times X_i
\]</span>
sendo que</p>
<p><span class="math display">\[
  P(X|Y=1) = \dfrac{P(X~\text{e}~Y=0)}{P(Y=0)}.
\]</span></p>
<p>As probabilidades condicionais são
<span class="math display">\[
  P((X=0|Y=1) = \dfrac{P(X=0~\text{e}~Y=1)}{P(Y=1)}= \dfrac{0}{\dfrac{1}{2}}= 0
\]</span></p>
<p><span class="math display">\[
  P((X=1|Y=1) = \dfrac{P(X=1~\text{e}~Y=1)}{P(Y=1)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]</span></p>
<p><span class="math display">\[
  P((X=2|Y=1) = \dfrac{P(X=2~\text{e}~Y=1)}{P(Y=1)}= \dfrac{\dfrac{2}{8}}{\dfrac{1}{2}}= \dfrac{1}{2}
\]</span></p>
<p><span class="math display">\[
  P((X=3|Y=1) = \dfrac{P(X=3~\text{e}~Y=1)}{P(Y=1)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]</span></p>
<p>Com essas probabilidades condicionais calcula-se a esperança de <span class="math inline">\(X\)</span> condicionada a <span class="math inline">\(Y=1\)</span></p>
<p><span class="math display">\[
  E(X|Y=1) = 0 + \frac{1}{4} \times 1 + \frac{1}{2}\times 2 + \dfrac{1}{3} \times 3 = 2
\]</span>
Portanto a <span class="math inline">\(E(X|Y=1) = 2\)</span>.</p>
<p>O valor de <span class="math inline">\(E[E(X|Y)]\)</span> é calculado da seguinte forma</p>
<p><span class="math display">\[
  E[E(X|Y)] = \sum_{j=1}^{k} P(Y_j)\times E(X|Y_j)
\]</span>
onde <span class="math inline">\(j=1,\ldots,k\)</span>. Assim sendo, para o exemplo numérico fica</p>
<p><span class="math display">\[
  E[E(X|Y)] = P(Y=0) \times E(X|Y=0) + P(Y=1) \times E(X|Y=1)
\]</span>
colocando os valores calculados
<span class="math display">\[
  E[E(X|Y)] = \dfrac{1}{2} \times 1 + \frac{1}{2} \times 2 = 1,5 
\]</span>
Note que <span class="math inline">\(E(X)\)</span> calculando anteriormente é, de fato, 1,5. Portanto confirma-se através do exemplo numérico que</p>
<p><span class="math display">\[
  E[E(X|Y)] = E(X).
\]</span></p>
</div>
<div id="variância-condicionada" class="section level3">
<h3><span class="header-section-number">6.1.4</span> Variância condicionada</h3>
<p>A variância condicional como o próprio nome diz é a variância de uma variável condicionada ao valor de uma outra variável. Por isso o seu cálculo necessíta a probabilidade condicional e a esperança condicionada. Neste caso, além da esperança condicional da variável em si, é necessário calcular a esperança condicional da variável elevada ao quadrado. Ou seja,</p>
<p><span class="math display">\[
  P(X=x|Y=y) = \dfrac{P (X=x~\cap~Y=y)}{P(Y=y)}
\]</span></p>
<p>para calcular a esperança condicionada de <span class="math inline">\(X\)</span> dado <span class="math inline">\(Y\)</span></p>
<p><span class="math display">\[
  E(X_i|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i.
\]</span></p>
<p>e a esperança condicionada de <span class="math inline">\(X^2\)</span> dado <span class="math inline">\(Y\)</span></p>
<p><span class="math display">\[
  E(X_i^2|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i^2.
\]</span>
para então calcular</p>
<p><span class="math display">\[
  Var(X|Y=c) = E(X^2|Y=c) - [E(X|Y=c)]^2.
\]</span></p>
<p><strong>Exemplo sobre a variância condicionada</strong></p>
<p>Exemplo 5.1.4 da página 114 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Com base nas variáveis do exemplo do time de volei, calcule <span class="math inline">\(Var(Y|X=1)\)</span>.</p>
<p><strong>Resposta</strong>:</p>
<p>É necessário calcular <span class="math inline">\(P(Y=0|X=1)\)</span> e <span class="math inline">\(P(Y=1|X=1)\)</span></p>
<p><span class="math display">\[
  P(Y=0|X=1) = \dfrac{P(Y=0~\cap~X=1)}{P(X=1)} = \dfrac{\dfrac{2}{8}}{\dfrac{3}{8}}=\dfrac{2}{3}
\]</span>
e
<span class="math display">\[
  P(Y=1|X=1) = \dfrac{P(Y=1~\cap~X=1)}{P(X=1)} = \dfrac{\dfrac{1}{8}}{\dfrac{3}{8}}=\dfrac{1}{3}.
\]</span>
Assim
<span class="math display">\[
  E(Y|X=1) = P(Y=0|X=1) \times 0 + P(Y=1|X=1) \times 1
\]</span></p>
<p><span class="math display">\[
  E(Y|X=1) = \dfrac{2}{3} \times 0 + \dfrac{1}{3} \times 1 = \dfrac{1}{3}.
\]</span>
Para <span class="math inline">\(Y^2\)</span>
<span class="math display">\[
  E(Y^2|X=1) = P(Y=0|X=1) \times 0^2 + P(Y=1|X=1) \times 1^2
\]</span></p>
<p><span class="math display">\[
  E(Y|X=1) = \dfrac{2}{3} \times 0^2 + \dfrac{1}{3} \times 1^2 = \dfrac{1}{3}.
\]</span></p>
<p>Portanto,</p>
<p><span class="math display">\[
  Var(Y|X=1) = E(Y^2|X=1) - [E(Y|X=1)]^2
\]</span></p>
<p><span class="math display">\[
  Var(Y|X=1) = \dfrac{1}{3} - [\dfrac{1}{3}]^2 
\]</span></p>
<p><span class="math display">\[
  Var(Y|X=1) = \dfrac{1}{3} - \dfrac{1}{9} = \dfrac{2}{9} 
\]</span></p>
<p><strong>Outro exemplo numérico sobre variância condicionada</strong></p>
<p>Exemplo 5.1.5 na página 114 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Sejam as variáveis <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> do exemplo numérico do time de volei. Calcule <span class="math inline">\(Var(X|Y=0)\)</span> e <span class="math inline">\(Var(X|Y=1)\)</span>.</p>
<p><strong>Resposta</strong>:</p>
<p>É necessário calcular</p>
<p><span class="math display">\[
  P(X=x|Y=y) = \dfrac{P (X=x~\cap~Y=y)}{P(Y=y)}
\]</span></p>
<p>para poder calcular a esperança condicionada de <span class="math inline">\(X\)</span> dado <span class="math inline">\(Y\)</span></p>
<p><span class="math display">\[
  E(X_i|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i.
\]</span></p>
<p>e a esperança condicionada de <span class="math inline">\(X^2\)</span> dado <span class="math inline">\(Y\)</span></p>
<p><span class="math display">\[
  E(X_i^2|Y=c) = \sum_{i=1}^{n} P(X_i| Y=c) \times X_i^2.
\]</span>
para então calcular</p>
<p><span class="math display">\[
  Var(X|Y=c) = E(X^2|Y=c) - [E(X|Y=c)]^2.
\]</span>
Já estão calculados</p>
<p><span class="math display">\[
  P((X=0|Y=0) = \dfrac{P(X=0~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]</span></p>
<p><span class="math display">\[
  P((X=1|Y=0) = \dfrac{P(X=1~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{2}{8}}{\dfrac{1}{2}}= \dfrac{1}{2}
\]</span></p>
<p><span class="math display">\[
  P((X=2|Y=0) = \dfrac{P(X=2~\text{e}~Y=0)}{P(Y=0)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]</span></p>
<p><span class="math display">\[
  P((X=3|Y=0) = \dfrac{P(X=3~\text{e}~Y=0)}{P(Y=0)}= \dfrac{0}{\dfrac{1}{2}}= 0
\]</span>
e
<span class="math display">\[
  P((X=0|Y=1) = \dfrac{P(X=0~\text{e}~Y=1)}{P(Y=1)}= \dfrac{0}{\dfrac{1}{2}}= 0
\]</span></p>
<p><span class="math display">\[
  P((X=1|Y=1) = \dfrac{P(X=1~\text{e}~Y=1)}{P(Y=1)}= \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}
\]</span></p>
<p><span class="math display">\[
  P((X=2|Y=1) = \dfrac{P(X=2~\text{e}~Y=1)}{P(Y=1)} \dfrac{\dfrac{2}{8}}{\dfrac{1}{2}}= \dfrac{1}{2}
\]</span></p>
<p><span class="math display">\[
  P((X=3|Y=1) = \dfrac{P(X=3~\text{e}~Y=1)}{P(Y=1)} \dfrac{\dfrac{1}{8}}{\dfrac{1}{2}}= \dfrac{1}{4}.
\]</span></p>
<p>Também já estão calculados</p>
<p><span class="math display">\[
  E(X|Y=0) = \frac{1}{4}\times 0 + \frac{1}{2} \times 1 + \frac{1}{4}\times 2 + 0 \times 3 = 1
\]</span>
e
<span class="math display">\[
  E(X|Y=1) = 0 + \frac{1}{4} \times 1 + \frac{1}{2}\times 2 + \dfrac{1}{3} \times 3 = 2.
\]</span>
Faltam ser calculadas as <span class="math inline">\(E(X^2|Y=0)\)</span> e <span class="math inline">\(E(X^2|Y=1)\)</span>.</p>
<p><span class="math display">\[\begin{multline}
  E(X^2|Y=0) = P(X=0|Y=0) \times 0^2 + P(X=1|Y=0)\times 1^2 +\\
  P(X=2|Y=0) \times 2^2 + P(X=3|Y=0) \times 3^2
\end{multline}\]</span>
<span class="math display">\[
  E(X^2|Y=0) = \dfrac{1}{4} \times 0^2 + \dfrac{1}{2}\times 1^2 +
  \dfrac{1}{4} \times 2^2 + 0 \times 3^2 = 1,5.
\]</span>
e
<span class="math display">\[\begin{multline}
  E(X^2|Y=1) = P(X=0|Y=1) \times 0^2 + P(X=1|Y=1)\times 1^2 +\\
  P(X=2|Y=1) \times 2^2 + P(X=3|Y=1) \times 3^2
\end{multline}\]</span>
<span class="math display">\[
  E(X^2|Y=1) = 0 \times 0^2 + \dfrac{1}{4}\times 1^2 +
  \dfrac{1}{2} \times 2^2 + \dfrac{1}{4} \times 3^2 = 4,5.
\]</span></p>
<p>Portanto, as variâncias condicionadas são</p>
<p><span class="math display">\[
  Var(X|Y=0) = E(X^2|Y=0) - [E(X|Y=0)]^2 = 1,5 - 1^2 = 0,5.
\]</span></p>
<p><span class="math display">\[
  Var(X|Y=1) = E(X^2|Y=1) - [E(X|Y=1)]^2 = 4,5 - 2^2 = 0,5.
\]</span>
Note que a variância condicional é sempre ou quase sempre menor do que a variância incondicional, ou seja,</p>
<p><span class="math display">\[
  Var(X|Y) \leq Var(X)
\]</span>
e
<span class="math display">\[
  Var(Y|X) \leq Var(Y).
\]</span></p>
<p>Por outro lado, Esperança condicional pode ser menor ou maior ou igual a esperança incondicional. Ou seja,</p>
<p><span class="math display">\[
  E(X|Y) &gt;=&lt;E(X)
\]</span>
e
<span class="math display">\[
  E(Y|X) &gt;=&lt;E(Y)
\]</span></p>
<p>Para entender essas relações, toma-se o exemplo do time de volei.</p>
<p>Se é garantido que o primeiro jogo vitória, ou seja, dado que <span class="math inline">\(Y=1\)</span>, o número de vitórias esperado aumenta.Ao contrário, se o primeiro jogo é, com certeza, derrota, o número de vitórias esperado diminui.</p>
<p>No caso da variância, condicional ou não, é uma media de dispersão. O fato do resultado do primeiro jogo ser dado, seja o resultado qual for, diminui o núero de resultados possíveis. Por isso, a variância condicional ser quase sempre menor.</p>
<p>Se as variáveis <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> forem independentes, isso significa</p>
<p><span class="math display">\[
  P(X|Y) = P(X)
\]</span>
e
<span class="math display">\[
  E(X|Y) = E(X)
\]</span>
e
<span class="math display">\[
  Var(X|Y) = Var(X).
\]</span>
Obviamente, também</p>
<p><span class="math display">\[
  P(Y|X)= P(Y)
\]</span>
e
<span class="math display">\[
  E(Y|X) = E(Y)
\]</span>
e
<span class="math display">\[
  Var(Y|X) = Var(Y).
\]</span></p>
</div>
<div id="decomposição-da-variância" class="section level3">
<h3><span class="header-section-number">6.1.5</span> Decomposição da Variância</h3>
<p>A decomposição da variância entrega uma relação interessante</p>
<p><span class="math display">\[
  Var(X) = Var[E(X|Y)] + E[Var(X|Y)]
\]</span></p>
<p><strong>Exemplo sobre a decomposição da variância</strong></p>
<p>Exemplo 5.1.6 da página 115 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Tomando o exemplo do time de volei, calcule <span class="math inline">\(E[Var(X|Y)]\)</span> e <span class="math inline">\(Var[E(X|Y)]\)</span></p>
<p><strong>Resposta</strong>:</p>
<p><span class="math display">\[
  E[Var(X|Y)] = Var(X|Y=0) \times P(Y=0) + Var(X|Y=1) \times P(Y=1)
\]</span></p>
<p><span class="math display">\[
  E[Var(X|Y)] = 0,5 \times 0,5 + 0,5 \times 0,5
\]</span></p>
<p><span class="math display">\[
  E[Var(X|Y)] = 0,5.
\]</span></p>
<p>No caso da <span class="math inline">\(Var[E(X|Y)]\)</span> é necessário calcular <span class="math inline">\(E\{[E(X|Y)]^2\}\)</span>, pois</p>
<p><span class="math display">\[
  Var[E(X|Y)] = E\{[E(X|Y)]^2\} - \{E[E(X|Y)]\}^2
\]</span></p>
<p>Então,</p>
<p><span class="math display">\[
  E\{[E(X|Y)]^2\} = E[E(X|Y=0)]^2\times P(Y=0) + E[E(X|Y=1)]^2\times P(Y=1) 
\]</span></p>
<p><span class="math display">\[
  E\{[E(X|Y)]^2\} = 1^2\times 0,5 + 2^2\times 0,5 
\]</span></p>
<p><span class="math display">\[
  E\{[E(X|Y)]^2\} = 2,5 
\]</span>
Portanto,</p>
<p><span class="math display">\[
  Var[E(X|Y)] = E\{[E(X|Y)]^2\} - \{E[E(X|Y)]\}^2 
\]</span></p>
<p><span class="math display">\[
  Var[E(X|Y)] = 2,5 - (1,5)^2 
\]</span></p>
<p><span class="math display">\[
  Var[E(X|Y)] = 2,5 - 2,25 
\]</span></p>
<p><span class="math display">\[
  Var[E(X|Y)] = 0,25
\]</span></p>
</div>
</div>
<div id="distribuição-de-probabilidade-conjunta-de-variáveis-aleatórias-contínuas" class="section level2">
<h2><span class="header-section-number">6.2</span> Distribuição de probabilidade conjunta de variáveis aleatórias contínuas</h2>
<p>Se as variáveis aleatórias forem contínuas, o procedimento é similar a da situação com uma variável. Neste caso haverá duas integrais no caso de duas variáveis.</p>
<div id="função-densidade-de-probabilidade-conjunta" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Função densidade de probabilidade conjunta</h3>
<p>Define-se uma função densidade de probabilidade (f.d.p.) conjunta <span class="math inline">\(f(x,y)\)</span> de tal forma que a probabilidade de <span class="math inline">\(x\)</span> estar entre os valores <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> e de <span class="math inline">\(y\)</span> estar entre <span class="math inline">\(c\)</span> e <span class="math inline">\(d\)</span> é dada por:</p>
<p><span class="math display" id="eq:FdpConjunta">\[
  P(a &lt; x &lt; b ~\text{ e }~ c &lt; y &lt; d) = \int_{c}^{d}\int_{a}^{b}f(x,y)~\text{d}x \text{d}y
  \tag{6.2}
\]</span>
Ou seja, a função densidade probabilidade conjunta, assim como a distribuição de probabilidade conjunta discreta, entrega a probabilidade para os intervalos definidos entre as duas ou mais variáveis.</p>
<p>Diferentemente da situação das variáveis aleatórias discretas, no caso de uma ou mais variáveis aleatórias contínuas a probabilidade só pode ser calculada para um intervalo pois,</p>
<p><span class="math display">\[
  P(X=x_0~~\text{e}~~Y=y_0) = 0,
\]</span>
mesmo que <span class="math inline">\(X=x_0\)</span> e <span class="math inline">\(Y=y_0\)</span> sejam eventos possíveis.</p>
<p>A função desnidade de probabilidade conjunta deve seguir as mesmas propriedades da f.d.p. para uma variável, ou seja,</p>
<ul>
<li><p>não pode ser negativa e;</p>
<p><span class="math display">\[
  f(x,y) \geq 0
\]</span></p></li>
<li><p>a soma de todas as probabilidades tem de ser igual a 1.</p></li>
</ul>
<p><span class="math display">\[
  \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}f(x,y)~\text{d}x \text{d}y = 1.
\]</span></p>
<p><strong>Exemplo numérico sobre a f.d.p. contínua e conjunta</strong></p>
<p>Exemplo 5.2.1 da página 118 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. seja a função</p>
<p><span class="math display">\[\begin{equation}
  f(x,y) = 
    \begin{cases}
      Axy,~~\text{para}~~0 &lt; x &lt; 1~~\text{e}~~0 &lt; y &lt; 1 \\
      \\
      0, ~~\text{para os demais valores}
    \end{cases}
\end{equation}\]</span>
Calcule o valor de <span class="math inline">\(A\)</span> para que <span class="math inline">\(f(x,y)\)</span> seja uma função densidade de probabilidade.</p>
<p><strong>Resposta</strong>:</p>
<p>Para que <span class="math inline">\(f(x,y)\)</span> seja uma f.d.p., deve atender a</p>
<p><span class="math display">\[
  \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}f(x,y)~\text{d}x \text{d}y = 1.
\]</span>
No caso específico do exemplo numérico, sabendo que tanto <span class="math inline">\(x\)</span> como <span class="math inline">\(y\)</span> variam entre zero e um se tem</p>
<p><span class="math display">\[
  \int_{0}^{1}\int_{0}^{1}f(x,y)~\text{d}x \text{d}y = 1
\]</span></p>
<p><span class="math display">\[
  \int_{0}^{1}\int_{0}^{1}Axy ~\text{d}x \text{d}y = 1
\]</span></p>
<p><span class="math display">\[
  \int_{0}^{1}Ay\int_{0}^{1}x~\text{d}x \text{d}y = 1
\]</span>
a regra de integração para uma função como a do exemplo numérico é de somar 1 a potência da variável para a qual está sendo integrada e dividir pelo resultado da soma da potência.
<span class="math display">\[
  \int_{0}^{1}Ay\left[ \dfrac{x^2}{2} \right]_{0}^{1} \text{d}y = 1
\]</span>
assim se calcula a diferença para <span class="math inline">\(x=1\)</span> e <span class="math inline">\(x=0\)</span>
<span class="math display">\[
  \int_{0}^{1}Ay\left[ \dfrac{1^2}{2} - \dfrac{0^2}{2} \right] \text{d}y = 1
\]</span>
e obtém=se a diferença
<span class="math display">\[
  \int_{0}^{1}Ay\dfrac{1}{2} \text{d}y = 1.
\]</span></p>
<p>Como <span class="math inline">\(A\)</span> e <span class="math inline">\(1/2\)</span> são constantes, coloca-se para fora da integral</p>
<p><span class="math display">\[
  \dfrac{A}{2}\int_{0}^{1}y~\text{d}y = 1
\]</span></p>
<p>a integral para a variável <span class="math inline">\(y\)</span> fica</p>
<p><span class="math display">\[
  \dfrac{A}{2}\left[ \dfrac{y^2}{2} \right]_{0}^{1}~\text{d}y = 1
\]</span></p>
<p>Calcula-se para <span class="math inline">\(y=1\)</span> e <span class="math inline">\(y=0\)</span>
<span class="math display">\[
  \dfrac{A}{2}\left[  \dfrac{1^2}{2} - \dfrac{0^2}{2} \right] = 1
\]</span></p>
<p>e obtém-se a diferença</p>
<p><span class="math display">\[
  \dfrac{A}{2}\dfrac{1}{2} = 1
\]</span></p>
<p><span class="math display">\[
  \dfrac{A}{4} = 1
\]</span>
Portanto</p>
<p><span class="math display">\[
  A=4
\]</span>
Assim a função <span class="math inline">\(f(x,y)\)</span> do exemplo numérico fica</p>
<p><span class="math display">\[\begin{equation}
  f(x,y) = 
    \begin{cases}
      4xy,~~\text{para}~~0 &lt; x &lt; 1~~\text{e}~~0 &lt; y &lt; 1 \\
      0, ~~\text{para os demais valores}
    \end{cases}
\end{equation}\]</span></p>
<p><strong>Outro exemplo numérico sobre a função densidade de probabilidade conjunta</strong></p>
<p>Exemplo 5.2.2 da página 119 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Dada a f.d.p. do exemplo numérico anterior</p>
<p><span class="math display">\[\begin{equation}
  f(x,y) = 
    \begin{cases}
      4xy,~~\text{para}~~0 &lt; x &lt; 1~~\text{e}~~0 &lt; y &lt; 1 \\
      \\
      0, ~~\text{para os demais valores}
    \end{cases}
\end{equation}\]</span></p>
<p>Calcule a probabilidade de <span class="math inline">\(x\)</span> estar entre 0,2 e 0,4 e de <span class="math inline">\(y\)</span> estar entre 0,6 e 0,8.</p>
<p><strong>Resposta</strong>:</p>
<p>A probabilidade conjunta é dada diretamente pela integral da função densidade de probabilidade</p>
<p><span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = \int_{0,6}^{0,8}\int_{0,2}^{0,4}f(x,y)~\text{d}x \text{d}y
\]</span></p>
<p><span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = \int_{0,6}^{0,8}\int_{0,2}^{0,4}4xy~\text{d}x \text{d}y
\]</span></p>
<p><span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = \int_{0,6}^{0,8}4y\int_{0,2}^{0,4}x~\text{d}x \text{d}y
\]</span>
integrando para <span class="math inline">\(x\)</span>
<span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = \int_{0,6}^{0,8}4y\left[\dfrac{x^2}{2} \right]_{0,2}^{0,4}~\text{d}y
\]</span>
calculando para <span class="math inline">\(x=0,2\)</span> e <span class="math inline">\(x=0,4\)</span>
<span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = \int_{0,6}^{0,8}4y\left[\dfrac{(0,4)^2}{2} - \dfrac{(0,2)^2}{2} \right]~\text{d}y
\]</span>
calculando a diferença para intervalo
<span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = \int_{0,6}^{0,8}4y\left[0,08 - 0,04 \right]~\text{d}y
\]</span></p>
<p><span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = \int_{0,6}^{0,8}0,24y~\text{d}y
\]</span>
Como 0,24 é constante, coloca-se para fora da integral
<span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = 0,24\int_{0,6}^{0,8}y~\text{d}y
\]</span></p>
<p><span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = 0,24\left[  \dfrac{y^2}{2}\right]_{0,6}^{0,8}
\]</span></p>
<p><span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = 0,24\left[  \dfrac{(0,8)^2}{2} - \dfrac{(0,6)^2}{2}\right]
\]</span></p>
<p><span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = 0,24\left[  \dfrac{0,64}{2} - \dfrac{0,36}{2}\right]
\]</span></p>
<p><span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = 0,24\times 0,14
\]</span></p>
<p><span class="math display">\[
  P(0,2 &lt; x &lt; 0,4~~\text{ e }~~0,6 &lt; y &lt; 0,8) = 0,0336
\]</span></p>
</div>
<div id="função-densidade-de-probabilidade-marginal" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Função densidade de probabilidade marginal</h3>
<p>Para variáveis aleatórias discretas, a distribuição marginal de <span class="math inline">\(x\)</span> é encontrada somando-se as probabilidades para todos os valores de <span class="math inline">\(y\)</span>, e vice-versa.</p>
<p>No caso de variáveis aleatórias contínuas, a função densidade de probabilidade marginal de <span class="math inline">\(x\)</span>, denominada de <span class="math inline">\(g(x)\)</span>, é encontrada de forma análoga, ou seja, intengrando-se <span class="math inline">\(f(x,y)\)</span> em <span class="math inline">\(y\)</span>.</p>
<p>De maneira geral, a f.d.p. marginal de <span class="math inline">\(x\)</span> pode ser encontrada da seguinte forma,</p>
<p><span class="math display">\[
  g(x) = \int_{-\infty}^{+\infty} f(x,y) \text{d}y
\]</span></p>
<p><strong>Exemplo numérico sobre função densidade de probabilidade marginal</strong></p>
<p>Exemplo 5.2.3 da página 120 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Seja a função densidade de probabilidade conjunta do exemplo numérico anterior, calcule as f.d.p. marginais de <span class="math inline">\(x\)</span> e de <span class="math inline">\(y\)</span>.</p>
<p><strong>Resposta</strong>:</p>
<p>Como se encontra a f.d.p. marginal de <span class="math inline">\(x\)</span> integrando <span class="math inline">\(f(x,y)\)</span> em <span class="math inline">\(y\)</span></p>
<p><span class="math display">\[
  g(x) = \int_{-\infty}^{+\infty} f(x,y) \text{d}y
\]</span></p>
<p>no caso do exemplo numérico é</p>
<p><span class="math display">\[
  g(x) = \int_{0}^{1} 4xy~ \text{d}y.
\]</span>
Ou seja,</p>
<p><span class="math display">\[
  g(x) = 4x\int_{0}^{1} y~ \text{d}y
\]</span></p>
<p><span class="math display">\[
  g(x) = 4x\left[ \dfrac{y^2}{2} \right]_{0}^{1}
\]</span></p>
<p><span class="math display">\[
  g(x) = 4x\dfrac{1}{2}
\]</span></p>
<p><span class="math display">\[
  g(x) = 2x
\]</span></p>
<p>De forma análoga, a f.d.p. marginal de <span class="math inline">\(y\)</span>, denotada como <span class="math inline">\(h(y)\)</span> é a integral de <span class="math inline">\(f(x,y)\)</span> em <span class="math inline">\(x\)</span>
<span class="math display">\[
hg(y) = \int_{-\infty}^{+\infty} f(x,y) \text{d}x
\]</span>
Assim, para o exemplo numérico fica</p>
<p><span class="math display">\[
  h(y) = \int_{0}^{1} 4xy~ \text{d}x.
\]</span></p>
<p><span class="math display">\[
  h(y) = 4y\int_{0}^{1} x~ \text{d}x
\]</span></p>
<p><span class="math display">\[
  h(y) = 4y\left[ \dfrac{x^2}{2} \right]_{0}^{1}
\]</span></p>
<p><span class="math display">\[
  h(y) = 4y\dfrac{1}{2}
\]</span></p>
<p><span class="math display">\[
  h(y) = 2y
\]</span></p>
<p><strong>Outro exemplo numérico sobre a f.d.p. marginal</strong></p>
<p>Exemplo 5.2.4 da página 121 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Seja a f.d.p. conjunta apresentada anteriormente</p>
<p><span class="math display">\[\begin{equation}
  f(x,y) = 
    \begin{cases}
      4xy,~~\text{para}~~0 &lt; x &lt; 1~~\text{e}~~0 &lt; y &lt; 1 \\
      \\
      0, ~~\text{para os demais valores}
    \end{cases}
\end{equation}\]</span>
calcule a probabilidade de <span class="math inline">\(x\)</span> estar entre 0,3 e 0,7.</p>
<p><strong>Resposta</strong>:</p>
<p>Note que é necessário integrar a f.d.p. conjunta em <span class="math inline">\(y\)</span> nos seus limites definidos para a função, para obter a f.d.p. marginal de <span class="math inline">\(x\)</span> o que permite calcular a probabilidade somente de <span class="math inline">\(x\)</span>. No exemplo numérico anterior já foi calculado o <span class="math inline">\(g(x)\)</span> que é</p>
<p><span class="math display">\[
  g(x) = \int_{0}^{1} 4xy~ \text{d}y = 2x
\]</span></p>
<p>Portanto,</p>
<p><span class="math display">\[
  P(0,3 &lt; x &lt; 0,7) = \int_{0,3}^{0,7}2x \text{d}x
\]</span></p>
<p><span class="math display">\[
  P(0,3 &lt; x &lt; 0,7) = \left[ x^2 \right]_{0,3}^{0,7} = 0,7^2 - 0,3^2
\]</span></p>
<p><span class="math display">\[
  P(0,3 &lt; x &lt; 0,7) = 0,48 - 0,09
\]</span></p>
<p><span class="math display">\[
  P(0,3 &lt; x &lt; 0,7) = 0,4.
\]</span></p>
</div>
<div id="probabilidade-condicional" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Probabilidade condicional</h3>
<p>A probabilidade condicional conjunta definido no contexto discreto é</p>
<p><span class="math display">\[
  P(X=x|Y=y) = \dfrac{P (X=x~\cap~Y=y)}{P(Y=y)}.
\]</span>
A <span class="math inline">\(P(X=x~\cap~Y=y)\)</span> corresponde a probabilidade conjunta, que no contexto contínuo corresponde a probabilidade conjunta dada pela função <span class="math inline">\(f(x,y)\)</span>.</p>
<p>A <span class="math inline">\(P(Y=y)\)</span> corresponde a probabilidade marginal, que no contexto contínuo corresponde a probabilidade marginal dada pela função <span class="math inline">\(h(y)\)</span>.</p>
<p>Portanto a probabilidade condicional no contexto contínuo, denotado como <span class="math inline">\(f_{x|y}\)</span> pode ser definido da seguinte forma</p>
<p><span class="math display">\[
  f_{x|y} = \dfrac{f(x,y)}{h(y)}
\]</span></p>
<p>Ou seja, a f.d.p. condicional de <span class="math inline">\(x\)</span> dado <span class="math inline">\(y\)</span>.</p>
<p>De forma análoga, a f.d.p. condicional de <span class="math inline">\(y\)</span> dado <span class="math inline">\(x\)</span>, denotado como <span class="math inline">\(f_{y|x}\)</span> pode ser definido como</p>
<p><span class="math display">\[
  f_{y|x} = \dfrac{f(x,y)}{g(x)}
\]</span>
onde <span class="math inline">\(g(x)\)</span> é f.d.p. marginal de <span class="math inline">\(x\)</span>.</p>
<p><strong>Exemplo numérico sobre probabilidade marginal</strong></p>
<p>Exemplo 5.2.5 da página 121 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>.</p>
<p>Seja a f.d.p. dos exemplos numéricos anteriores</p>
<p><span class="math display">\[\begin{equation}
  f(x,y) = 
    \begin{cases}
      4xy,~~\text{para}~~0 &lt; x &lt; 1~~\text{e}~~0 &lt; y &lt; 1 \\
      \\
      0, ~~\text{para os demais valores}
    \end{cases}
\end{equation}\]</span>
calcule a f.d.p. condicional de <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</p>
<p><strong>Resposta</strong>:</p>
<p>No caso da f.d.p. condicional de <span class="math inline">\(x\)</span> dado <span class="math inline">\(y\)</span> é necessário calcular</p>
<p><span class="math display">\[
  f_{x|y} = \dfrac{f(x,y)}{h(y)}
\]</span>
e já estão disponíveis <span class="math inline">\(f(x,y)\)</span></p>
<p><span class="math display">\[
  f(x,y) = 4xy
\]</span>
para <span class="math inline">\(0 &lt; x &lt;1\)</span> e <span class="math inline">\(0 &lt; y &lt; 1\)</span>, dado pelo exemplo corrente, e a f.d.p. marginal de <span class="math inline">\(y\)</span>,</p>
<p><span class="math display">\[
  h(y) = 2y
\]</span>
que foi calculada no exemplo numérico anterior para <span class="math inline">\(0 &lt; y &lt; 1\)</span>.</p>
<p>Portanto,
<span class="math display">\[
  f_{x|y} = \dfrac{f(x,y)}{h(y)} = \dfrac{4xy}{2y}
\]</span></p>
<p><span class="math display">\[
  f_{x|y} = 2x
\]</span>
De forma análoga, a f.d.p. condicianal de <span class="math inline">\(y\)</span> dado <span class="math inline">\(x\)</span>
<span class="math display">\[
  f_{y|x} = \dfrac{f(x,y)}{g(x)}
\]</span>
Note que já estão disponíveis as partes necessárias para o cálculo de <span class="math inline">\(f_{y|x}\)</span></p>
<p><span class="math display">\[
  f_{y|x} = \dfrac{f(x,y)}{g(x)} = \frac{4xy}{2x}
\]</span></p>
<p><span class="math display">\[
  f_{y|x} = 2y
\]</span></p>
<p><strong>Verificação da independência de duas variáveis</strong></p>
<p>Note que quando ocorre</p>
<p><span class="math display">\[
  f_{x|y} = g(x)
\]</span>
e
<span class="math display">\[
  f_{y|x} = h(y)
\]</span>
ou seja, as f.d.p. condicionais são iguais a f.d.p. incondicionais ou marginais, pode-se concluir que as variáveis são independentes.</p>
<p>Dessa forma, é valido afirmar que</p>
<p><span class="math display" id="eq:IgualdadeParaVariaveisIndependentes">\[
  f(x,y) = g(x) \times h(y).
  \tag{6.3}
\]</span></p>
<p>Note que no último exemplo numérico, verifca-se que</p>
<p><span class="math display">\[
  f(x,y) = g(x) \times h(y) = 2x \times 2y = 4xy
\]</span></p>
<p>A igualdade <a href="distribuição-de-variáveis-aleátórias-conjunta.html#eq:IgualdadeParaVariaveisIndependentes">(6.3)</a> é válida sempre que as variáveis forem independentes. Uma demonstração dessa igualdade é apresentada no apêndice do capítulo 5 de <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>.</p>
<p>Do ponto de vista matemático, é possível verificar se as variáveis em uma função densidade de probabilidade conjunta são independentes, é verificar se é possível ser fatorada em funções para cada variável separadamente. Ou seja, o produto de uma função só para <span class="math inline">\(x\)</span> e de uma função só para <span class="math inline">\(y\)</span>, como se obteve no último exemplo numérico.</p>
</div>
<div id="esperança-matemática-de-x" class="section level3">
<h3><span class="header-section-number">6.2.4</span> Esperança matemática de <span class="math inline">\(x\)</span></h3>
<p>Para o cálculo da esperança matemática de <span class="math inline">\(x\)</span>, a semelhança da esperança matemática para uma única variável, é possível realizar diretamente através de um f.d.p. conjunta <span class="math inline">\(f(x,y)\)</span>, ou através de uma f.d.p. marginal de <span class="math inline">\(x\)</span>
<span class="math display">\[
  g(x) = \int_{-\infty}^{+\infty} f(x,y) \text{d}y,
\]</span></p>
<p>Partindo-se da f.d.p. conjunta, obtém-se <span class="math inline">\(E(x)\)</span> calculando</p>
<p><span class="math display">\[
  E(x) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x~f(x)~\text{d}x\text{d}y.
\]</span>
Já partindo de uma f.d.p. marginal de <span class="math inline">\(x\)</span>, obtém=se calculando</p>
<p><span class="math display">\[
  E(x) = \int_{-\infty}^{+\infty} x~g(x)~\text{d}x.
\]</span></p>
<p><strong>Exemplo numérico sobre o valor esperado de uma váriável a partir de uma f.d.p. conjunta</strong></p>
<p>Exemplo 5.2.6 da página 122 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Seja a f.d.p. conjunta dos exemplos numéricos anteriores,
<span class="math display">\[\begin{equation}
  f(x,y) = 
    \begin{cases}
      4xy,~~\text{para}~~0 &lt; x &lt; 1~~\text{e}~~0 &lt; y &lt; 1 \\
      \\
      0, ~~\text{para os demais valores}
    \end{cases}
\end{equation}\]</span>
calcule <span class="math inline">\(E(x)\)</span>.</p>
<p><strong>Resposta</strong>:</p>
<p>Partindo da f.d.p. conjunta, é necessário calcular</p>
<p><span class="math display">\[
  E(x) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x~f(x)~\text{d}x\text{d}y
\]</span></p>
<p><span class="math display">\[
  E(x) = \int_{0}^{1} \int_{0}^{1} x~4xy~\text{d}x\text{d}y
\]</span></p>
<p><span class="math display">\[
  E(x) = 4\int_{0}^{1} \int_{0}^{1} x^2y~\text{d}x\text{d}y
\]</span></p>
<p><span class="math display">\[
  E(x) = 4\int_{0}^{1}y \int_{0}^{1} x^2~\text{d}x\text{d}y
\]</span></p>
<p><span class="math display">\[
  E(x) = 4\int_{0}^{1}y \left[ \dfrac{x^3}{3} \right]_{0}^{1}~\text{d}y
\]</span></p>
<p><span class="math display">\[
  E(x) = \dfrac{4}{3}\int_{0}^{1}y~\text{d}y
\]</span></p>
<p><span class="math display">\[
  E(x) = \dfrac{4}{3}\left[ \dfrac{y^2}{2} \right]_{0}^{1}~\text{d}y
\]</span></p>
<p><span class="math display">\[
  E(x) = \dfrac{4}{3}\times \dfrac{1}{2}
\]</span></p>
<p><span class="math display">\[
  E(x) = \dfrac{2}{3}
\]</span></p>
<p>Partindo da f.d.p. marginal <span class="math inline">\(g(x)\)</span>
<span class="math display">\[
  g(x) = 2x
\]</span>
é necessário calcular
<span class="math display">\[
  E(x) = \int_{-\infty}^{+\infty} x~g(x)~\text{d}x.
\]</span></p>
<p><span class="math display">\[
  E(x) = \int_{0}^{1} x~2x~\text{d}x.
\]</span></p>
<p><span class="math display">\[
  E(x) = 2\int_{0}^{1} x^2~\text{d}x.
\]</span></p>
<p><span class="math display">\[
  E(x) = 2\left[ \dfrac{x^3}{3} \right]_{0}^{1}
\]</span></p>
<p><span class="math display">\[
  E(x) = 2 \times \frac{1}{3}
\]</span></p>
<p><span class="math display">\[
  E(x) = \frac{2}{3}
\]</span>
que é o mesmo valor do cálculo partindo da f.d.p. conjunta.</p>
<p>Note que o cálculo para <span class="math inline">\(E(y)\)</span> é similar ao cálculo de <span class="math inline">\(E(x)\)</span>, tanto a partir da f.d.p. conjunta como a partir da f.d.p. marginal de <span class="math inline">\(y\)</span>. Ou seja,</p>
<p><span class="math display">\[
  E(y) = \dfrac{2}{3}.
\]</span>
A verificação é deixada como exercício.</p>
</div>
<div id="variância-de-x" class="section level3">
<h3><span class="header-section-number">6.2.5</span> Variância de <span class="math inline">\(x\)</span></h3>
<p>Assim como a esperança matemática de <span class="math inline">\(x\)</span>, a variância de <span class="math inline">\(x\)</span> também pode ser obtida através da f.d.p. conjunta <span class="math inline">\(f(x,y)\)</span> de <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, ou através da f.d.p. marginal de <span class="math inline">\(x\)</span>, denotada como <span class="math inline">\(g(x)\)</span>. A semelhança da variância para uma única variável, pode-se usar a fórmula da definição</p>
<p><span class="math display">\[
  Var(x) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}[x - E(x)]^2~f(x,y) ~\text{d}x \text{d}y
\]</span>
ou a versão alternativa
<span class="math display">\[
  Var(x) = \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} x^2~f(x,y)~\text{d}x\text{d}y - \left[ \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}x~f(x,y)~\text{d}x \text{d}y \right]^2
\]</span>
que, apesar das integrais, é a velha e conhecida média dos quadrados menos o quadrado da média.</p>
<p>Partindo da f.d.p. marginal <span class="math inline">\(g(x)\)</span>, pode-se usar a fórmula da definição</p>
<p><span class="math display">\[
  Var(x) = \int_{-\infty}^{+\infty}[X - E(x)]^2~g(x) ~\text{d}x
\]</span>
ou a versão alternativa
<span class="math display">\[
  Var(x) = \int_{-\infty}^{+\infty} x^2~g(x)~\text{d}x - \left[ \int_{-\infty}^{+\infty}x~g(x)~\text{d}x \right]^2
\]</span></p>
<p><strong>Exemplo sobre a variância de <span class="math inline">\(x\)</span></strong></p>
<p>Exemplo 5.2.7 da página 127 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Seja a f.d.p. conjunta dos exemplos numéricos anteriores</p>
<p><span class="math display">\[\begin{equation}
  f(x,y) = 
    \begin{cases}
      4xy,~~\text{para}~~0 &lt; x &lt; 1~~\text{e}~~0 &lt; y &lt; 1 \\
      \\
      0, ~~\text{para os demais valores}
    \end{cases}
\end{equation}\]</span></p>
<p>calcule <span class="math inline">\(Var(x)\)</span>.</p>
<p><strong>Resposta</strong>:</p>
<p>Como já foi calculado a esperança de <span class="math inline">\(x\)</span> utilizando a f.d.p. marginal de <span class="math inline">\(x\)</span>
<span class="math display">\[
  E(x) = \int_{-\infty}^{+\infty} x~g(x)~\text{d}x = \dfrac{2}{3}
\]</span>
e usando a fórmula alternativa da variância</p>
<p><span class="math display">\[
  Var(x) = \int_{-\infty}^{+\infty} x^2~g(x)~\text{d}x - \left[ \int_{-\infty}^{+\infty}x~g(x)~\text{d}x \right]^2
\]</span></p>
<p><span class="math display">\[
  Var(x) = \int_{0}^{1} x^2~g(x)~\text{d}x - \left[ \dfrac{2}{3}\right]^2
\]</span>
e falta calcular a esperança dos quadrados, a semelhaça do cálculo da variância de uma única variável.</p>
<p><span class="math display">\[
  Var(x) = \int_{0}^{1} x^2~2x~\text{d}x - \left[ \dfrac{4}{9}\right]
\]</span></p>
<p><span class="math display">\[
  Var(x) = 2\int_{0}^{1} x^3~\text{d}x - \left[ \dfrac{4}{9}\right]
\]</span></p>
<p><span class="math display">\[
  Var(x) = 2\left[ \dfrac{x^4}{4} \right]_{0}^{1} - \left[ \dfrac{4}{9}\right]
\]</span></p>
<p><span class="math display">\[
  Var(x) = \dfrac{1}{2} - \dfrac{4}{9}
\]</span></p>
<p><span class="math display">\[
  Var(x) = \dfrac{2-1}{18}
\]</span></p>
<p><span class="math display">\[
  Var(x) = \dfrac{1}{18}
\]</span></p>
<p>A variância de <span class="math inline">\(y\)</span> é deixado como exercício.</p>
</div>
<div id="covariância-entre-x-e-y" class="section level3">
<h3><span class="header-section-number">6.2.6</span> Covariância entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span></h3>
<p>Lembrando que a covariância apresentada na parte de estísticas descritivas é dado por</p>
<p><span class="math display">\[
  cov(x,y) = E[x - E(x)][y - E(y)] = E(xy) - E(x)E(y).
\]</span></p>
<p>Em termos de f.d.p. conjunta fica da seguinte forma considerando a definição de covariância</p>
<p><span class="math display">\[
  Cov(x,y) = \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}[x - E(x)][y - E(y)]~f(x,y)~\text{d}x\text{d}y 
\]</span>
e a forma alternativa
<span class="math display">\[
  Cov(x,y) = \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}~xy~f(x,y)~\text{d}x\text{d}y - \int_{-\infty}^{+\infty}x~g(x)~\text{d}x \int_{-\infty}^{+\infty}y~h(y)~\text{d}y
\]</span></p>
<p><strong>Exemplo numérico sobre a covariância entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span></strong></p>
<p>Exemplo 5.2.8 da página 124 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Seja a f.d.p. conjunta dos exemplos numéricos anteriores</p>
<p><span class="math display">\[\begin{equation}
  f(x,y) = 
    \begin{cases}
      4xy,~~\text{para}~~0 &lt; x &lt; 1~~\text{e}~~0 &lt; y &lt; 1 \\
      \\
      0, ~~\text{para os demais valores}
    \end{cases}
\end{equation}\]</span></p>
<p>calcule a covariância entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</p>
<p><strong>Resposta</strong>:</p>
<p>Como já foram calculadas as médias de <span class="math inline">\(x\)</span> e de <span class="math inline">\(y\)</span>, utiliza-se a forma alternativa da covariância. Assim só falta calcular <span class="math inline">\(E(xy)\)</span>.</p>
<p><span class="math display">\[
  Cov(x,y) = \int_{0}^{1}\int_{0}^{1}~xy~4xy~\text{d}x\text{d}y - \dfrac{2}{3}\times \dfrac{2}{3}
\]</span></p>
<p><span class="math display">\[
  Cov(x,y) = 4\int_{0}^{1}y^2\int_{0}^{1}~x^2~\text{d}x\text{d}y - \dfrac{4}{9}
\]</span></p>
<p><span class="math display">\[
  Cov(x,y) = 4\int_{0}^{1}y^2\left[ \dfrac{x^3}{3} \right]_{0}^{1}~\text{d}y - \dfrac{4}{9}
\]</span></p>
<p><span class="math display">\[
  Cov(x,y) = 4\int_{0}^{1}y^2\left[ \dfrac{1}{3} \right]~\text{d}y - \dfrac{4}{9}
\]</span></p>
<p><span class="math display">\[
  Cov(x,y) = \dfrac{4}{3}\int_{0}^{1}y^2~\text{d}y - \dfrac{2}{3}\times \dfrac{2}{3}
\]</span></p>
<p><span class="math display">\[
  Cov(x,y) = \dfrac{4}{3}\left[ \dfrac{y^3}{3} \right]_{0}^{1} - \dfrac{4}{9}
\]</span></p>
<p><span class="math display">\[
  Cov(x,y) = \dfrac{4}{9} - \dfrac{4}{9}
\]</span></p>
<p><span class="math display">\[
  Cov(x,y) = 0
\]</span></p>
<p>Note que já era esperado que a covariância fosse igual a zero, uma vez que verificou-se que as variáveis <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> do exemplo númerico desenvolvido são independentes.</p>
<p><strong>Um outro exemplo numérico sobre f.d.p. conjunta</strong></p>
<p>Exemplo 5.2.9 da página 125 do <span class="citation">Sartoris (<a href="#ref-Sartoris2013" role="doc-biblioref">2013</a>)</span>. Seja a função</p>
<p><span class="math display">\[\begin{equation}
  f(x,y) = 
    \begin{cases}
      B\left( x^2 + y^2 \right),~~\text{para}~~0 &lt; x &lt; 1~~\text{e}~~0 &lt; y &lt; 1 \\
      \\
      0, ~~\text{para os demais valores}
    \end{cases}
\end{equation}\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Calcule o valor da constatne <span class="math inline">\(B\)</span>, de modo que função seja f.d.p. conjunta;</li>
<li>Calcule as f.d.p. marginais de <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>;</li>
<li>Calcule as f.d.p. condicionais de <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>;</li>
<li>Verifique se <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> são variáveis independentes;</li>
<li>Calcule <span class="math inline">\(P(x &lt;0,5|y=0,5)\)</span>;</li>
</ol>
<p><strong>Respostas</strong>:</p>
<ol style="list-style-type: lower-alpha">
<li>Para ser uma função f.d.p. precisa atender a seguinte condição</li>
</ol>
<p><span class="math display">\[
  \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}f(x,y)~\text{d}x\text{d}y = 1
\]</span></p>
<p>como <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> variam entre zero e um é possível definir os limites das integrais</p>
<p><span class="math display">\[
  \int_{0}^{1}\int_{0}^{1}f(x,y)~\text{d}x\text{d}y = 1
\]</span>
incluindo a função dada
<span class="math display">\[
  \int_{0}^{1}\int_{0}^{1}B(x^2 + y^2)~\text{d}x\text{d}y = 1
\]</span>
Como <span class="math inline">\(B\)</span> é constante
<span class="math display">\[
  B\int_{0}^{1}\int_{0}^{1}(x^2 + y^2)~\text{d}x\text{d}y = 1
\]</span>
lembre-se que <span class="math inline">\(x^0 = 1\)</span>
<span class="math display">\[
  B\int_{0}^{1}\int_{0}^{1}(x^2 + y^2)~\text{d}x\text{d}y = 1
\]</span></p>
<p><span class="math display">\[
  B\int_{0}^{1} \left[ \dfrac{x^3}{3} + y^2x \right]_{0}^{1}~\text{d}y = 1
\]</span></p>
<p><span class="math display">\[
  B\int_{0}^{1} \left[ \dfrac{1}{3} + y^2 \right]~\text{d}y = 1
\]</span></p>
<p><span class="math display">\[
  B\left[ \dfrac{1}{3}y + \dfrac{y^3}{3} \right]_{0}^{1} = 1
\]</span></p>
<p><span class="math display">\[
  B\left[ \dfrac{1}{3} + \dfrac{1}{3} \right] = 1
\]</span></p>
<p><span class="math display">\[
  B\times \dfrac{2}{3} = 1
\]</span></p>
<p><span class="math display">\[
  B = \dfrac{3}{2}
\]</span></p>
<p>Portanto, a f.d.p. conjunta deste exemplo numérico fica
<span class="math display">\[
  f(x,y) = \int_{0}^{1}\int_{0}^{1}\dfrac{3}{2}(x^2 + y^2)~\text{d}x\text{d}y
\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Para obter a f.d.p. marginal de <span class="math inline">\(x\)</span> , <span class="math inline">\(g(x)\)</span>, é necessário integrar <span class="math inline">\(f(x,y)\)</span> em <span class="math inline">\(y\)</span>. Ou seja,</li>
</ol>
<p><span class="math display">\[
  g(x) = \int_{0}^{1}\dfrac{3}{2}(x^2 + y^2)~\text{d}y
\]</span>
lembrando que <span class="math inline">\(y^0=1\)</span>
<span class="math display">\[
  g(x) = \dfrac{3}{2}\left[ x^2y + \dfrac{y^3}{3} \right]_{0}^{1}~\text{d}y
\]</span></p>
<p><span class="math display">\[
  g(x) = \dfrac{3}{2}\left[ x^2 + \dfrac{1}{3} \right]
\]</span>
Procede-se de forma similar para obter a f.d.p. marginal de <span class="math inline">\(y\)</span>, <span class="math inline">\(h(y)\)</span>, ou seja, integrando <span class="math inline">\(f(x,y)\)</span> em <span class="math inline">\(x\)</span></p>
<p><span class="math display">\[
  h(y) = \int_{0}^{1}\dfrac{3}{2}(x^2 + y^2)~\text{d}x
\]</span>
lembrando que <span class="math inline">\(x^0 = 1\)</span>
<span class="math display">\[
  h(y) = \dfrac{3}{2}\left[ \dfrac{x^3}{3}+ y^2x \right]_{0}^{1}
\]</span></p>
<p><span class="math display">\[
  h(y) = \dfrac{3}{2}\left[ \dfrac{1}{3}+ y^2 \right]
\]</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Como se tem <span class="math inline">\(f(x,y)\)</span> e já foram calculadas as f.d.p. marginais de <span class="math inline">\(x\)</span> e de <span class="math inline">\(y\)</span>, fica fácil obter as f.d.p. condicionais de <span class="math inline">\(x\)</span> e de <span class="math inline">\(y\)</span>.</li>
</ol>
<p>Para <span class="math inline">\(f_{x|y}\)</span></p>
<p><span class="math display">\[
  f_{x|y} = \dfrac{f(x,y)}{h(y)} = \dfrac{\dfrac{3}{2}(x^2 + y^2)}{\dfrac{3}{2}\left( \dfrac{1}{3} + y^2 \right)}
\]</span></p>
<p><span class="math display">\[
  f_{x|y} = \dfrac{(x^2 + y^2)}{\left( \dfrac{1}{3} + y^2 \right)}
\]</span></p>
<p>e para <span class="math inline">\(f_{y|x}\)</span></p>
<p><span class="math display">\[
  f_{y|x} = \dfrac{f(x,y)}{g(x)} = \dfrac{\dfrac{3}{2}(x^2 + y^2)}{\dfrac{3}{2}\left(x^2 + \dfrac{1}{3} \right)}
\]</span></p>
<p><span class="math display">\[
  f_{y|x} = \dfrac{(x^2 + y^2)}{\left(x^2 + \dfrac{1}{3} \right)}
\]</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Como</li>
</ol>
<p><span class="math display">\[
  f_{x|y} \neq g(x)
\]</span>
e</p>
<p><span class="math display">\[
  f_{y|x} \neq h(y)
\]</span></p>
<p>conclui-se que as variáveis <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> neste exemplo numérico não são independentes.</p>
<p>Mas, com resolução de (b) e de (c), já seria possível verificar que a função <span class="math inline">\((x^2 + y^2)\)</span> não é fatorável de modo a obter uma função só de <span class="math inline">\(x\)</span> ou outra só de <span class="math inline">\(y\)</span>.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Como se trata de uma probabilidade condiciional, é necessário fazer uso da f.d.p. condicional de <span class="math inline">\(x\)</span> dado <span class="math inline">\(y=0,5\)</span>. A <span class="math inline">\(f_{x|y}\)</span> é</li>
</ol>
<p><span class="math display">\[
  f_{x|y} = \dfrac{(x^2 + y^2)}{\left( \dfrac{1}{3} + y^2 \right)}
\]</span></p>
<p>fazendo <span class="math inline">\(y=1/2\)</span> a <span class="math inline">\(f_{x|y}\)</span> fica</p>
<p><span class="math display">\[
  f_{x|y} = \dfrac{x^2 + \left( \dfrac{1}{2}\right)^2}{ \dfrac{1}{3} + \left( \dfrac{1}{2} \right)^2} =  \dfrac{x^2 + \dfrac{1}{4}}{ \dfrac{1}{3} + \dfrac{1}{4}} = \dfrac{x^2 + \dfrac{1}{4}}{ \dfrac{7}{12}}
\]</span></p>
<p><span class="math display">\[
  f_{x|y} = \dfrac{12}{7}\left(x^2 + \dfrac{1}{4}\right)
\]</span></p>
<p>Agora falta definir que <span class="math inline">\(x&lt;0,5\)</span>. uma vez que já e dado que <span class="math inline">\(y=0,5\)</span>. Assim,</p>
<p><span class="math display">\[
P(x&lt;0,5~|~y=0,5) = \dfrac{12}{7} \int_{0}^{0,5}\left(x^2 + \dfrac{1}{4}\right)~\text{d}x = \dfrac{12}{7} \left[\dfrac{x^3}{3} + \dfrac{1}{4}x  \right]_{0}^{0,5} =  \dfrac{12}{7} \left[\dfrac{1}{24} + \dfrac{1}{8} \right] 
\]</span></p>
<p><span class="math display">\[
P(x&lt;0,5~|~y=0,5) = \left[\dfrac{1}{14} + \dfrac{3}{14} \right] 
\]</span></p>
<p><span class="math display">\[
P(x&lt;0,5~|~y=0,5) = \dfrac{2}{7} \cong 0,2857 
\]</span></p>

</div>
</div>
</div>
<h3>Referências</h3>
<div id="refs" class="references">
<div id="ref-Sartoris2013">
<p>Sartoris, Alexandre. 2013. <em>Estatística e Introdução à Econometria</em>. 2nd ed. São Paulo: Saraiva.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="variável-aleatória-contínua.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimadores.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["EstatEcon.pdf", "EstatEcon.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
